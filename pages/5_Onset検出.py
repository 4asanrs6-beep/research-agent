"""Onsetæ¤œå‡º Phase 1 â€” ã‚¹ã‚¿ãƒ¼æ ªå…±é€šç‚¹ç™ºè¦‹ + è¿½åŠ ã‚¹ã‚¿ãƒ¼æ ªç™ºè¦‹ + åˆå‹•ç‰¹å®š

ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¹ã‚¿ãƒ¼æ ªã‚’æŒ‡å®š â†’ å…±é€šç‰¹å¾´é‡ã‚’ç™ºè¦‹ â†’ è¿½åŠ ã‚¹ã‚¿ãƒ¼æ ªã‚’ç™ºè¦‹ â†’ åˆå‹•æ—¥ã‚’ç‰¹å®š
"""

import json
import threading
import time as _time
from datetime import date, datetime, timedelta
from pathlib import Path

import numpy as np
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st

from config import MARKET_DATA_DIR, JQUANTS_API_KEY
from data.cache import DataCache
from data.jquants_provider import JQuantsProvider
from core.styles import apply_reuters_style
from core.onset_detector.discoverer import (
    WIDE_FEATURE_DESCRIPTIONS_JP,
    ONSET_SIGNAL_NAMES_JP,
)

# åˆå‹•ã‚·ã‚°ãƒŠãƒ«ã®ç•¥ç§°ï¼ˆè¡¨ç¤ºç”¨ï¼‰
SIGNAL_JP_SHORT = {
    "volume_surge": "å‡ºæ¥é«˜æ€¥å¢—",
    "quiet_accumulation": "é™çš„è²·ã„é›†ã‚",
    "consecutive_accumulation": "ç¶™ç¶šçš„è“„ç©",
    "obv_breakout": "å‡ºæ¥é«˜ç´¯è¨ˆçªç ´",
    "bb_squeeze": "ä¾¡æ ¼å¸¯åç¸®",
    "volatility_compression": "å€¤å‹•ãåç¸®",
    "higher_lows": "å®‰å€¤åˆ‡ã‚Šä¸Šã’",
    "range_breakout": "é«˜å€¤ãƒ–ãƒ¬ã‚¤ã‚¯",
    "ma_crossover": "å¹³å‡ç·šã‚¯ãƒ­ã‚¹",
    "up_volume_dominance": "è²·ã„å‡ºæ¥é«˜å„ªå‹¢",
}

st.set_page_config(page_title="Onsetæ¤œå‡º", page_icon="R", layout="wide")
apply_reuters_style()

RESULTS_DIR = Path("storage/onset_results")


def _save_results(result: dict) -> Path:
    """çµæœã‚’JSONä¿å­˜"""
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    path = RESULTS_DIR / f"phase1_{ts}.json"

    serializable = {}
    for key in ("common_features", "additional_stars", "onset_dates",
                "ai_interpretation", "warnings"):
        val = result.get(key)
        if val is not None:
            serializable[key] = val

    # star_stocks / all_stars
    for key in ("star_stocks", "all_stars"):
        val = result.get(key)
        if val:
            serializable[key] = val

    serializable["saved_at"] = ts

    with open(path, "w", encoding="utf-8") as f:
        json.dump(serializable, f, ensure_ascii=False, indent=2, default=str)
    return path


def _load_results(path: Path) -> dict:
    """ä¿å­˜æ¸ˆã¿çµæœã‚’èª­ã¿è¾¼ã¿"""
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def _list_saved_results() -> list[Path]:
    if not RESULTS_DIR.exists():
        return []
    return sorted(RESULTS_DIR.glob("phase1_*.json"), reverse=True)


@st.cache_resource
def get_data_provider():
    cache = DataCache(MARKET_DATA_DIR)
    return JQuantsProvider(api_key=JQUANTS_API_KEY, cache=cache)


# ---------------------------------------------------------------------------
# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
# ---------------------------------------------------------------------------
def _run_phase1_thread(progress_dict: dict, provider, config):
    """Phase 1ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ"""
    try:
        from core.onset_detector import run_phase1_discovery

        def on_progress(step, total, msg):
            progress_dict["step"] = step
            progress_dict["total"] = total
            progress_dict["message"] = msg
            progress_dict["pct"] = step / total if total > 0 else 0

        result = run_phase1_discovery(
            data_provider=provider,
            config=config,
            progress_callback=on_progress,
        )
        progress_dict["_result"] = result
        progress_dict["pct"] = 1.0
        progress_dict["message"] = "å®Œäº†"
    except Exception as e:
        import traceback
        progress_dict["error"] = str(e)
        progress_dict["traceback"] = traceback.format_exc()
        progress_dict["pct"] = 1.0


# ---------------------------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸
# ---------------------------------------------------------------------------
def main():
    st.markdown(
        '<p style="font-size:18px;font-weight:700;margin-bottom:2px;">'
        'Onsetæ¤œå‡º Phase 1 '
        '<span style="font-size:12px;color:#888;font-weight:400;">'
        'â€” å…±é€šç‚¹ç™ºè¦‹ + è¿½åŠ ã‚¹ã‚¿ãƒ¼æ ª + åˆå‹•ç‰¹å®š</span></p>',
        unsafe_allow_html=True,
    )

    # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
    with st.sidebar:
        st.markdown("### Onsetæ¤œå‡º è¨­å®š")

        st.markdown("**åˆ†ææœŸé–“**")
        col_d1, col_d2 = st.columns(2)
        with col_d1:
            start_date = st.date_input(
                "é–‹å§‹æ—¥", value=date.today() - timedelta(days=365),
                key="onset_start_date",
                help="åˆ†æå¯¾è±¡ã®é–‹å§‹æ—¥",
            )
        with col_d2:
            end_date = st.date_input(
                "çµ‚äº†æ—¥", value=date.today(),
                key="onset_end_date",
                help="åˆ†æå¯¾è±¡ã®çµ‚äº†æ—¥",
            )

        st.markdown("**å¯¾è±¡ãƒ•ã‚£ãƒ«ã‚¿**")
        scan_min_market_cap = st.number_input(
            "æœ€ä½æ™‚ä¾¡ç·é¡ï¼ˆå„„å††ï¼‰",
            min_value=0, max_value=10000, value=0, step=50,
            help="yfinanceã§å®Ÿéš›ã®æ™‚ä¾¡ç·é¡ã‚’å–å¾—ã—ãƒ•ã‚£ãƒ«ã‚¿ã€‚0ã§ç„¡åŠ¹ã€‚"
            "åˆå›å–å¾—ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ãŒ30æ—¥é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¾ã™ã€‚"
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã‚¹ã‚¿ãƒ¼æ ªã¯é™¤å¤–ã•ã‚Œã¾ã›ã‚“",
        )

        st.markdown("**ç™ºè¦‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**")
        discovery_min_precision = st.slider(
            "ã‚³ãƒ³ãƒœæœ€ä½ç²¾åº¦", 0.05, 0.50, 0.15, 0.05,
            help="ç‰¹å¾´é‡ã‚³ãƒ³ãƒœã®æœ€ä½ç²¾åº¦ã€‚ä½ã„ã»ã©å¤šãã®ã‚³ãƒ³ãƒœãŒå€™è£œã«ãªã‚Šã¾ã™",
        )
        discovery_min_recall = st.slider(
            "ã‚³ãƒ³ãƒœæœ€ä½å†ç¾ç‡", 0.10, 0.80, 0.30, 0.05,
            help="ç‰¹å¾´é‡ã‚³ãƒ³ãƒœã®æœ€ä½å†ç¾ç‡ã€‚é«˜ã„ã»ã©å¤šãã®ã‚¹ã‚¿ãƒ¼æ ªã‚’ã‚«ãƒãƒ¼ã™ã‚‹ã‚³ãƒ³ãƒœã®ã¿æ¡ç”¨",
        )
        discovery_max_additional = st.slider(
            "è¿½åŠ ã‚¹ã‚¿ãƒ¼æ ªä¸Šé™", 5, 100, 30,
            help="ã‚³ãƒ³ãƒœæ¡ä»¶ã§ç™ºè¦‹ã™ã‚‹è¿½åŠ ã‚¹ã‚¿ãƒ¼æ ªã®æœ€å¤§æ•°",
        )

        st.markdown("**ä¿¡ç”¨å–å¼•ãƒ‡ãƒ¼ã‚¿**")
        use_margin = st.checkbox(
            "ä¿¡ç”¨å–å¼•ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨", value=True,
            help="ç´„52å›ã®è¿½åŠ APIã‚³ãƒ¼ãƒ«ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹ï¼‰ã€‚ä¿¡ç”¨è²·ã„æ®‹ãƒ»è²¸å€Ÿå€ç‡ç­‰ã®ç‰¹å¾´é‡ã‚’è¿½åŠ ",
        )

        st.markdown("**AIè§£é‡ˆ**")
        use_ai = st.checkbox(
            "Claude CLIã§çµæœã‚’è§£é‡ˆ", value=True,
            help="Claude Code CLIã‚’ä½¿ã£ã¦ç™ºè¦‹çµæœã‚’è‡ªç„¶è¨€èªã§è§£é‡ˆãƒ»èª¬æ˜ã—ã¾ã™",
        )

        # éå»çµæœèª­è¾¼
        st.markdown("---")
        saved_list = _list_saved_results()
        st.markdown(f"**éå»ã®å®Ÿè¡Œçµæœ** ({len(saved_list)}ä»¶)")
        if saved_list:
            selected_file = st.selectbox(
                "èª­ã¿è¾¼ã‚€çµæœã‚’é¸æŠ",
                ["ï¼ˆé¸æŠã—ã¦ãã ã•ã„ï¼‰"] + [sp.name for sp in saved_list[:20]],
                key="onset_history_select",
            )
            if st.button("çµæœã‚’èª­ã¿è¾¼ã‚€", key="onset_load_history"):
                if selected_file != "ï¼ˆé¸æŠã—ã¦ãã ã•ã„ï¼‰":
                    sp = RESULTS_DIR / selected_file
                    if sp.exists():
                        loaded = _load_results(sp)
                        st.session_state["onset_result"] = loaded
                        st.rerun()
        else:
            st.caption("å®Ÿè¡Œå¾Œã«è‡ªå‹•ä¿å­˜ã•ã‚Œã¾ã™")

    # --- ã‚¹ã‚¿ãƒ¼æ ªå…¥åŠ› ---
    st.markdown("### ã‚¹ã‚¿ãƒ¼æ ªã®æŒ‡å®š")

    # ã‚¹ã‚¿ãƒ¼æ ªåˆ†æçµæœã®æœ‰ç„¡
    ss_result = st.session_state.get("ss_result")
    has_ss_result = (
        ss_result is not None
        and hasattr(ss_result, "star_stocks")
        and ss_result.star_stocks
    )

    source_options = []
    if has_ss_result:
        source_options.append(
            f"ã‚¹ã‚¿ãƒ¼æ ªåˆ†æã®çµæœã‚’ä½¿ç”¨ï¼ˆ{len(ss_result.star_stocks)}ä»¶ï¼‰"
        )
    source_options.append("æ‰‹å‹•ã§ã‚³ãƒ¼ãƒ‰æŒ‡å®š")

    star_source = st.radio(
        "ã‚¹ã‚¿ãƒ¼æ ªã®æŒ‡å®šæ–¹æ³•",
        source_options,
        horizontal=True,
        help="ã€Œã‚¹ã‚¿ãƒ¼æ ªåˆ†æã€ãƒšãƒ¼ã‚¸ã®çµæœãŒã‚ã‚‹å ´åˆã¯ãã®ã¾ã¾å¼•ãç¶™ã’ã¾ã™",
    )

    user_star_codes = []

    if star_source.startswith("ã‚¹ã‚¿ãƒ¼æ ªåˆ†æã®çµæœ"):
        star_stocks_input = ss_result.star_stocks
        user_star_codes = [str(s["code"])[:4] for s in star_stocks_input]
        preview_df = pd.DataFrame([
            {
                "ã‚³ãƒ¼ãƒ‰": s["code"],
                "éŠ˜æŸ„å": s.get("name", ""),
                "è¶…éãƒªã‚¿ãƒ¼ãƒ³": f"{s.get('excess_return', 0):.1%}",
            }
            for s in star_stocks_input[:10]
        ])
        st.dataframe(preview_df, use_container_width=True, hide_index=True)
        if len(star_stocks_input) > 10:
            st.caption(f"...ä»– {len(star_stocks_input) - 10}ä»¶")
    else:
        codes_text = st.text_input(
            "ã‚¹ã‚¿ãƒ¼æ ªã‚³ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰",
            placeholder="6920, 5803, 7203, 6526, 6857",
            help="éå»ã«å¤§ããä¸Šæ˜‡ã—ãŸéŠ˜æŸ„ã®ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ï¼ˆ4æ¡ã§ã‚‚5æ¡ã§ã‚‚OKï¼‰",
        )
        if codes_text.strip():
            user_star_codes = [c.strip() for c in codes_text.split(",") if c.strip()]
            st.caption(f"{len(user_star_codes)}ä»¶æŒ‡å®š")

    # --- Configæ§‹ç¯‰ ---
    from core.onset_detector.config import OnsetDetectorConfig
    config = OnsetDetectorConfig(
        start_date=str(start_date),
        end_date=str(end_date),
        user_star_codes=user_star_codes,
        scan_min_market_cap=float(scan_min_market_cap),
        discovery_min_precision=discovery_min_precision,
        discovery_min_recall=discovery_min_recall,
        discovery_max_additional_stars=discovery_max_additional,
        use_ai_interpretation=use_ai,
        use_margin_features=use_margin,
    )

    # --- å®Ÿè¡Œãƒœã‚¿ãƒ³ ---
    st.markdown("---")
    col1, col2 = st.columns([2, 8])
    with col1:
        run_clicked = st.button(
            "Phase 1 å®Ÿè¡Œ", type="primary", use_container_width=True,
        )

    # --- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œï¼ˆsession_stateã§ã‚¹ãƒ¬ãƒƒãƒ‰ç®¡ç† â†’ ç”»é¢å¾©å¸°æ™‚ã‚‚ç¶™ç¶šï¼‰ ---
    if run_clicked:
        if not user_star_codes:
            st.warning("ã‚¹ã‚¿ãƒ¼æ ªã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return

        progress_dict = {
            "step": 0, "total": 8, "message": "é–‹å§‹...", "pct": 0.0,
            "_start_time": _time.time(),
        }
        provider = get_data_provider()

        thread = threading.Thread(
            target=_run_phase1_thread,
            args=(progress_dict, provider, config),
            daemon=True,
        )
        thread.start()

        # session_stateã«ä¿æŒ â†’ ç”»é¢å¾©å¸°æ™‚ã«ã‚‚å‚ç…§å¯èƒ½
        st.session_state["onset_thread"] = thread
        st.session_state["onset_progress"] = progress_dict

    # --- å®Ÿè¡Œä¸­ã‚¹ãƒ¬ãƒƒãƒ‰ã®ç›£è¦–ï¼ˆãƒšãƒ¼ã‚¸ãƒªãƒ­ãƒ¼ãƒ‰/å¾©å¸°æ™‚ã‚‚å‹•ä½œï¼‰ ---
    thread = st.session_state.get("onset_thread")
    progress_dict = st.session_state.get("onset_progress")

    if thread is not None and progress_dict is not None:
        if thread.is_alive():
            # ã¾ã å®Ÿè¡Œä¸­ â†’ é€²æ—è¡¨ç¤ºã—ã¦ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥
            pct = progress_dict.get("pct", 0.0)
            msg = progress_dict.get("message", "")
            step = progress_dict.get("step", 0)
            total = progress_dict.get("total", 7)
            start_time = progress_dict.get("_start_time", _time.time())
            elapsed = int(_time.time() - start_time)
            if elapsed >= 60:
                elapsed_str = f"{elapsed // 60}åˆ†{elapsed % 60:02d}ç§’"
            else:
                elapsed_str = f"{elapsed}ç§’"

            st.progress(min(pct, 0.99))
            st.markdown(
                f"**Step {step}/{total}**: {msg}ã€€ï¼ˆçµŒé: {elapsed_str}ï¼‰"
            )
            _time.sleep(1.0)
            st.rerun()
        else:
            # ã‚¹ãƒ¬ãƒƒãƒ‰å®Œäº† â†’ çµæœã‚’å–ã‚Šå‡ºã™
            thread.join()

            # session_stateã‹ã‚‰ã‚¯ãƒªã‚¢
            del st.session_state["onset_thread"]
            del st.session_state["onset_progress"]

            if "error" in progress_dict:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {progress_dict['error']}")
                if "traceback" in progress_dict:
                    with st.expander("è©³ç´°"):
                        st.code(progress_dict["traceback"])
            else:
                result = progress_dict.get("_result", {})
                if "error" in result:
                    st.warning(result["error"])
                else:
                    st.session_state["onset_result"] = result
                    saved_path = _save_results(result)
                    st.success(f"çµæœä¿å­˜å®Œäº†: {saved_path.name}")
                    st.rerun()

            return

    # --- çµæœè¡¨ç¤º ---
    result = st.session_state.get("onset_result")
    if result is None:
        st.info("ã€ŒPhase 1 å®Ÿè¡Œã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦é–‹å§‹ã—ã¦ãã ã•ã„")
        return

    _display_results(result)


def _normalize_ai_headers(text: str) -> str:
    """AIè§£é‡ˆã®Markdownãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆ#, ##, ###ï¼‰ã‚’ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã®å¤ªå­—ã«å¤‰æ›ã—ã€ãƒ•ã‚©ãƒ³ãƒˆã‚’å‡ä¸€ã«ã™ã‚‹"""
    import re
    text = re.sub(r'^#### (.+)$', r'**â–¸ \1**', text, flags=re.MULTILINE)
    text = re.sub(r'^### (.+)$', r'**â–¸ \1**', text, flags=re.MULTILINE)
    text = re.sub(r'^## (.+)$', r'\n**â–  \1**', text, flags=re.MULTILINE)
    text = re.sub(r'^# (.+)$', r'\n**â—† \1**', text, flags=re.MULTILINE)
    # è¡¨ï¼ˆ| ... |ï¼‰ã¯ãã®ã¾ã¾æ®‹ã™
    return text


def _section(title: str):
    """çµ±ä¸€ã•ã‚ŒãŸå°è¦‹å‡ºã—ï¼ˆh4ç›¸å½“ã€ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºæŠ‘åˆ¶ï¼‰"""
    st.markdown(
        f'<p style="font-size:13px;font-weight:700;margin:14px 0 4px 0;'
        f'border-bottom:1px solid #ddd;padding-bottom:3px;">{title}</p>',
        unsafe_allow_html=True,
    )


def _tag(label: str, color: str) -> str:
    """ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚¿ã‚°HTML"""
    return (
        f'<span style="background:{color};color:#fff;padding:1px 6px;'
        f'border-radius:3px;font-size:11px;font-weight:600;">{label}</span>'
    )


TAG_INPUT = _tag("å…¥åŠ›", "#1565C0")
TAG_FOUND = _tag("ç™ºè¦‹", "#E65100")


# ---------------------------------------------------------------------------
# çµæœãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆã‚³ãƒ”ãƒšç”¨ï¼‰
# ---------------------------------------------------------------------------
def _build_result_text(result: dict) -> str:
    """çµæœå…¨ä½“ã‚’ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
    lines = ["=" * 60, "Onsetæ¤œå‡º Phase 1 çµæœã‚µãƒãƒªãƒ¼", "=" * 60, ""]

    star_stocks = result.get("star_stocks", [])
    additional_stars = result.get("additional_stars", [])
    common_features = result.get("common_features", {})
    onset_dates = result.get("onset_dates", {})
    all_stars = result.get("all_stars", [])
    ai_interp = result.get("ai_interpretation", "")

    # ã‚µãƒãƒªãƒ¼
    n_onset = sum(1 for od in onset_dates.values() if od.get("onset_date"))
    best_combos = common_features.get("best_combos", [])
    base_rate = common_features.get("base_rate", 0)
    lines.append(f"å…¥åŠ›ã‚¹ã‚¿ãƒ¼æ ª: {len(star_stocks)}ä»¶")
    lines.append(f"è¿½åŠ ç™ºè¦‹: {len(additional_stars)}ä»¶")
    lines.append(f"åˆå‹•ç‰¹å®š: {n_onset}/{len(all_stars)}ä»¶")
    lines.append(f"ãƒ™ã‚¹ãƒˆã‚³ãƒ³ãƒœ: {len(best_combos)}ä»¶")
    lines.append("")

    # ç¢ºç‡ãƒ»ãƒªã‚¿ãƒ¼ãƒ³ã‚µãƒãƒªãƒ¼
    base_rate_universe = common_features.get("base_rate_universe", base_rate)
    n_universe = common_features.get("n_universe", 0)
    if best_combos:
        best = best_combos[0]
        best_names = " ã‹ã¤ ".join(best.get("features_jp", best["features"]))
        lines.append("--- ã‚¹ã‚¿ãƒ¼æ ªã«ãªã‚‹ç¢ºç‡ ---")
        # æ¯é›†å›£ç²¾åº¦ãŒè¨ˆç®—æ¸ˆã¿ã‹ç¢ºèª
        u_prec = best.get("universe_precision")
        if u_prec is not None and n_universe > 0:
            u_hits = best.get("universe_n_hits", 0)
            u_stars = best.get("universe_n_stars", 0)
            u_lift = u_prec / base_rate_universe if base_rate_universe > 0 else 0
            lines.append(f"  åˆ†æå¯¾è±¡: {n_universe:,}éŠ˜æŸ„ï¼ˆæ™‚ä¾¡ç·é¡ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆï¼‰")
            lines.append(f"  ã‚¹ã‚¿ãƒ¼æ ªãƒ™ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒˆ: {base_rate_universe:.2%}ï¼ˆä½•ã‚‚ã—ãªã„å ´åˆï¼‰")
            lines.append(f"  æ¡ä»¶ã€Œ{best_names}ã€ã‚’å¯¾è±¡æœŸé–“ä¸­ã«æº€ãŸã—ãŸéŠ˜æŸ„: {u_hits:,}ä»¶")
            lines.append(f"  ãã®ã†ã¡ã‚¹ã‚¿ãƒ¼æ ªã«ãªã£ãŸ: {u_stars}ä»¶ â†’ ç¢ºç‡ {u_prec:.1%}ï¼ˆ{u_lift:.1f}å€ï¼‰")
        else:
            lines.append(f"  å¸‚å ´ãƒ™ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒˆï¼ˆæ¡ä»¶ãªã—ï¼‰: {base_rate:.1%}")
            lines.append(f"  æ¡ä»¶ã€Œ{best_names}ã€ã‚’æº€ãŸã—ãŸå ´åˆ: {best['precision']:.0%}ï¼ˆ{best['lift']:.1f}å€ï¼‰")
        lines.append(f"  ã‚«ãƒãƒ¼ç‡: {best['recall']:.0%}ã®ã‚¹ã‚¿ãƒ¼æ ªã‚’ã‚«ãƒãƒ¼")
        lines.append("")

    max_returns = [
        od.get("max_return") or od.get("max_return_60d") or od.get("fwd_return_60d")
        for od in onset_dates.values()
        if od.get("onset_date") and (
            od.get("max_return") is not None or
            od.get("max_return_60d") is not None or
            od.get("fwd_return_60d") is not None
        )
    ]
    max_returns = [r for r in max_returns if r is not None]
    if max_returns:
        mean_ret = sum(max_returns) / len(max_returns)
        sorted_rets = sorted(max_returns)
        median_ret = sorted_rets[len(sorted_rets) // 2]
        lines.append("--- åˆå‹•å¾Œ æœ€å¤§åˆ°é”ãƒªã‚¿ãƒ¼ãƒ³çµ±è¨ˆ ---")
        lines.append(f"  å¹³å‡ æœ€å¤§ãƒªã‚¿ãƒ¼ãƒ³: {mean_ret:.1%}")
        lines.append(f"  ä¸­å¤®å€¤ æœ€å¤§ãƒªã‚¿ãƒ¼ãƒ³: {median_ret:.1%}")
        lines.append(f"  æœ€å¤§: {max(max_returns):.1%}  æœ€å°: {min(max_returns):.1%}")
        lines.append(f"  å¯¾è±¡éŠ˜æŸ„æ•°: {len(max_returns)}")
        lines.append("")

    # AIè§£é‡ˆ
    if ai_interp:
        lines += ["--- AIè§£é‡ˆ ---", ai_interp, ""]

    # å…±é€šç‰¹å¾´é‡
    signals = common_features.get("signals", [])
    useful = [s for s in signals if s.get("verdict") != "meaningless"]
    if useful:
        lines.append("--- åˆ¤åˆ¥ç‰¹å¾´é‡ (ã‚¹ã‚¿ãƒ¼æ ª vs éã‚¹ã‚¿ãƒ¼æ ª) ---")
        for s in useful[:10]:
            name = s.get("feature_jp", s["feature"])
            lines.append(
                f"  {name}: ã‚¹ã‚¿ãƒ¼={_fmt_val(s['pos_mean'])}  "
                f"éã‚¹ã‚¿ãƒ¼={_fmt_val(s['neg_mean'])}  "
                f"é–¾å€¤>={_fmt_val(s['threshold'])}  "
                f"J={s['j_stat']:.3f}  Lift={s['lift']:.1f}x"
            )
        lines.append("")

    # ã‚³ãƒ³ãƒœï¼ˆæ¯é›†å›£ç²¾åº¦å„ªå…ˆã€ãªã‘ã‚Œã°è¨“ç·´ç²¾åº¦ï¼‰
    if best_combos:
        lines.append("--- ãƒ™ã‚¹ãƒˆã‚³ãƒ³ãƒœï¼ˆæ¯é›†å›£ãƒ™ãƒ¼ã‚¹ï¼‰ ---")
        for i, c in enumerate(best_combos[:5]):
            names = " AND ".join(c.get("features_jp", c["features"]))
            u_prec = c.get("universe_precision")
            u_hits = c.get("universe_n_hits", 0)
            u_stars = c.get("universe_n_stars", 0)
            if u_prec is not None and u_hits > 0:
                u_lift = u_prec / base_rate_universe if base_rate_universe > 0 else 0
                lines.append(
                    f"  {i+1}. {names}  "
                    f"æ¯é›†å›£ç¢ºç‡={u_prec:.1%}ï¼ˆ{u_lift:.1f}å€ï¼‰ "
                    f"æ¡ä»¶åˆè‡´={u_hits}ä»¶ä¸­{u_stars}ä»¶ã‚¹ã‚¿ãƒ¼æ ª  "
                    f"ã‚«ãƒãƒ¼ç‡={c['recall']:.0%}"
                )
            else:
                tp = c.get("tp", 0)
                total_hits = c.get("total_hits", c.get("n_combo", "?"))
                lines.append(
                    f"  {i+1}. {names}  "
                    f"è¨“ç·´ç²¾åº¦={c['precision']:.0%}ï¼ˆå‚è€ƒï¼‰  "
                    f"ã‚«ãƒãƒ¼ç‡={c['recall']:.0%}  åˆè‡´={total_hits}ä»¶ä¸­{tp}ä»¶ã‚¹ã‚¿ãƒ¼æ ª"
                )
        lines.append("")

    # å…¨ã‚¹ã‚¿ãƒ¼æ ª + åˆå‹•
    lines.append("--- å…¨ã‚¹ã‚¿ãƒ¼æ ª + åˆå‹•æ—¥ ---")
    lines.append(f"{'ã‚³ãƒ¼ãƒ‰':<8} {'éŠ˜æŸ„å':<16} {'ç¨®åˆ¥':<4} {'åˆå‹•æ—¥':<12} "
                 f"{'Sig':>3} {'60då¾Œ':>7} ç™ºç«ã‚·ã‚°ãƒŠãƒ«")
    lines.append("-" * 90)
    for star in all_stars:
        code = str(star["code"])
        od = onset_dates.get(code, {})
        src = "å…¥åŠ›" if star.get("source") == "user" else "ç™ºè¦‹"
        onset = od.get("onset_date", "-")
        score = od.get("score", 0)
        max_r = od.get("max_return") or od.get("max_return_60d") or od.get("fwd_return_60d")
        fwd = f"{max_r:.1%}" if od.get("onset_date") and max_r is not None else "-"
        sigs = "ã€".join(SIGNAL_JP_SHORT.get(s, s) for s in od.get("signals", []))
        name = star.get("name", "")[:14]
        lines.append(f"{code:<8} {name:<16} {src:<4} {onset:<12} {score:>3} {fwd:>7} {sigs}")
    lines.append("")

    return "\n".join(lines)


# ---------------------------------------------------------------------------
# ç¢ºç‡ãƒ»ãƒªã‚¿ãƒ¼ãƒ³ã‚µãƒãƒªãƒ¼
# ---------------------------------------------------------------------------
def _display_probability_summary(result: dict):
    """ã‚¹ã‚¿ãƒ¼æ ªç¢ºç‡ã¨åˆå‹•å¾Œãƒªã‚¿ãƒ¼ãƒ³ã‚’ç›´æ„Ÿçš„ã«è¡¨ç¤º"""
    common_features = result.get("common_features", {})
    onset_dates = result.get("onset_dates", {})

    base_rate = common_features.get("base_rate", 0)
    base_rate_universe = common_features.get("base_rate_universe", base_rate)
    n_universe = common_features.get("n_universe", 0)
    best_combos = common_features.get("best_combos", [])

    # åˆå‹•å¾Œãƒªã‚¿ãƒ¼ãƒ³: onset_date ãŒã‚ã‚‹éŠ˜æŸ„ã®max_returnã‚’å„ªå…ˆåé›†
    ret_pairs = []  # (code, returnå€¤)
    for code, od in onset_dates.items():
        if not od.get("onset_date"):
            continue
        # max_returnï¼ˆæ–°ï¼‰ > max_return_60dï¼ˆæ—§ï¼‰ > fwd_return_60d ã®å„ªå…ˆé †ã§å–å¾—
        ret = od.get("max_return") or od.get("max_return_60d") or od.get("fwd_return_60d")
        if ret is None:
            continue
        ret_pairs.append((code, float(ret)))

    if not best_combos and not ret_pairs:
        return

    st.markdown("---")

    # ================================================================
    # ãƒ–ãƒ­ãƒƒã‚¯1: ã“ã®ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‚‰ä½•%ãŒã‚¹ã‚¿ãƒ¼æ ªã«ãªã£ãŸã‹ï¼Ÿ
    # ================================================================
    st.markdown(
        '<p style="font-size:14px;font-weight:700;margin:4px 0 8px 0;">'
        'â“ ã“ã®ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸéŠ˜æŸ„ã¯ã€ä½•%ãŒã‚¹ã‚¿ãƒ¼æ ªã«ãªã£ãŸã‹ï¼Ÿ</p>',
        unsafe_allow_html=True,
    )

    if best_combos:
        n_star_total = common_features.get("n_star", 0)
        has_universe = best_combos[0].get("universe_precision") is not None

        if has_universe and n_universe > 0:
            st.caption(
                f"ğŸ“Š åˆ†æå¯¾è±¡ {n_universe:,}éŠ˜æŸ„ã®ã†ã¡ã€å¯¾è±¡æœŸé–“ä¸­ã«ã„ã¤ã‹ã§ã‚‚æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„ã®ä½•%ãŒã‚¹ã‚¿ãƒ¼æ ªã«ãªã£ãŸã‹"
                f"ï¼ˆã‚¹ã‚¿ãƒ¼æ ªãƒ™ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒˆ = {base_rate_universe:.2%}ï¼‰"
            )

            # 0ä»¶åˆè‡´ï¼ˆéå­¦ç¿’ï¼‰ã¨ãã‚Œä»¥å¤–ã«åˆ†é›¢
            valid_combos = [c for c in best_combos[:5] if c.get("universe_n_hits", 0) > 0]
            overfit_combos = [c for c in best_combos[:5] if c.get("universe_n_hits", 0) == 0]

            for i, c in enumerate(valid_combos):
                u_prec = c.get("universe_precision", 0)
                u_hits = c.get("universe_n_hits", 0)
                u_stars = c.get("universe_n_stars", 0)
                u_lift = u_prec / base_rate_universe if base_rate_universe > 0 else 0
                recall = c.get("recall", 0)

                # ä¿¡é ¼åº¦
                if u_stars >= 5:
                    rel_icon, rel_label = "ğŸŸ¢", "ä¿¡é ¼åº¦: é«˜ï¼ˆNâ‰¥5ï¼‰"
                elif u_stars >= 3:
                    rel_icon, rel_label = "ğŸŸ¡", "ä¿¡é ¼åº¦: ä¸­ï¼ˆN=3ã€œ4ï¼‰"
                else:
                    rel_icon, rel_label = "ğŸ”´", "ä¿¡é ¼åº¦: ä½ï¼ˆNâ‰¤2 â€” å‚è€ƒå€¤ï¼‰"

                # æ¡ä»¶è¡Œã‚’é–¾å€¤ä»˜ãã§ç”Ÿæˆ
                cond_lines = _combo_cond_lines(c, numbered=True)

                with st.expander(
                    f"{rel_icon} **#{i+1}** â€” ã‚¹ã‚¿ãƒ¼æ ªç¢ºç‡ **{u_prec:.1%}**ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒˆã®{u_lift:.1f}å€ï¼‰ã€€"
                    f"æ¡ä»¶åˆè‡´: {u_hits}ä»¶ / ã†ã¡ã‚¹ã‚¿ãƒ¼æ ª: {u_stars}ä»¶ã€€ã‚«ãƒãƒ¼ç‡: {recall:.0%}",
                    expanded=(i == 0),
                ):
                    st.markdown("**ä»¥ä¸‹ã®æ¡ä»¶ã‚’å…¨ã¦åŒæ™‚ã«æº€ãŸã—ã¦ã„ã‚‹éŠ˜æŸ„:**")
                    for line in cond_lines:
                        st.markdown(line)
                    st.caption(rel_label)

            if overfit_combos:
                with st.expander(f"âš ï¸ æ¡ä»¶ãŒå³ã—ã™ãã‚‹ã‚³ãƒ³ãƒœï¼ˆæ¯é›†å›£ã§0ä»¶åˆè‡´ â€” å®Ÿç”¨å¤–ï¼‰ {len(overfit_combos)}ä»¶", expanded=False):
                    st.warning(
                        "ä»¥ä¸‹ã®ã‚³ãƒ³ãƒœã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã¯é«˜ç²¾åº¦ã§ã—ãŸãŒã€å…¨éŠ˜æŸ„Ã—è¤‡æ•°æ™‚ç‚¹ã®ã‚¹ã‚­ãƒ£ãƒ³ã§"
                        "ä¸€åº¦ã‚‚æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                        "æ¡ä»¶ãŒå³ã—ã™ãã¦å®Ÿéš›ã®ç›¸å ´ã§ã¯ç™ºå‹•ã—ãªã„ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚"
                    )
                    for i, c in enumerate(overfit_combos):
                        cond_lines = _combo_cond_lines(c, numbered=True)
                        with st.expander(
                            f"éå­¦ç¿’ã‚³ãƒ³ãƒœ #{i+1}  è¨“ç·´ç²¾åº¦={c['precision']:.0%}ï¼ˆå‚è€ƒã®ã¿ï¼‰ã€€ã‚«ãƒãƒ¼ç‡: {c['recall']:.0%}",
                            expanded=False,
                        ):
                            for line in cond_lines:
                                st.markdown(line)

            # å‚è€ƒ: åŒä¸€ãƒ‡ãƒ¼ã‚¿å†…ç²¾åº¦ï¼ˆéå­¦ç¿’æ³¨æ„ï¼‰
            with st.expander("å‚è€ƒ: åŒä¸€ãƒ‡ãƒ¼ã‚¿å†…ç²¾åº¦ï¼ˆéå­¦ç¿’æ³¨æ„ï¼‰", expanded=False):
                st.warning(
                    "ä»¥ä¸‹ã¯**åŒã˜ãƒ‡ãƒ¼ã‚¿ã§æ¡ä»¶ã‚’ç™ºè¦‹ãƒ»è©•ä¾¡ã—ãŸ**ç²¾åº¦ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ç²¾åº¦ï¼‰ã§ã™ã€‚"
                    "ã‚¹ã‚¿ãƒ¼æ ªãŒå°‘ãªã„å ´åˆã€100%ã«ãªã‚Šã‚„ã™ã**ä¿¡é ¼æ€§ãŒä½ã„**ã§ã™ã€‚"
                    "ä¸Šã®æ¯é›†å›£ç²¾åº¦ã®æ–¹ãŒå®Ÿæ…‹ã«è¿‘ã„å€¤ã§ã™ã€‚"
                )
                ref_rows = []
                for i, c in enumerate(best_combos[:5]):
                    features = c.get("features", [])
                    features_jp = c.get("features_jp", features)
                    names = " ã‹ã¤ ".join(features_jp)
                    tp = c.get("tp", 0)
                    total_hits = c.get("total_hits", c.get("n_combo", 0))
                    ref_rows.append({
                        "é †ä½": f"#{i+1}",
                        "æ¡ä»¶": names,
                        "è¨“ç·´ç²¾åº¦": f"{c['precision']:.0%}",
                        "Lift": f"{c['lift']:.1f}å€",
                        "åˆè‡´": f"{total_hits}ä»¶ä¸­{tp}ä»¶ã‚¹ã‚¿ãƒ¼æ ª",
                    })
                st.dataframe(pd.DataFrame(ref_rows), use_container_width=True, hide_index=True)

        else:
            # æ¯é›†å›£ç²¾åº¦ãŒãªã„å ´åˆï¼ˆæ—§ãƒ‡ãƒ¼ã‚¿äº’æ›ï¼‰
            small_sample_combos = [c for c in best_combos[:5] if c.get("tp", 0) < 5]
            if small_sample_combos:
                st.warning(
                    f"âš ï¸ **ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè­¦å‘Š**: åŒä¸€ãƒ‡ãƒ¼ã‚¿ã§æ¡ä»¶ã‚’ç™ºè¦‹ãƒ»è©•ä¾¡ã—ã¦ã„ã‚‹ãŸã‚"
                    f"ç²¾åº¦ãŒéå¤§è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
                    f"æ¯é›†å›£ç²¾åº¦ã¯å†å®Ÿè¡Œã™ã‚‹ã¨è¨ˆç®—ã•ã‚Œã¾ã™ã€‚"
                )

            st.caption(f"â€» å†å®Ÿè¡Œã™ã‚‹ã¨æ¯é›†å›£ç²¾åº¦ï¼ˆå…¨éŠ˜æŸ„Ã—è¤‡æ•°æ™‚ç‚¹ã‚¹ã‚­ãƒ£ãƒ³ï¼‰ãŒè¨ˆç®—ã•ã‚Œã¾ã™")
            for i, c in enumerate(best_combos[:5]):
                tp = c.get("tp", 0)
                total_hits = c.get("total_hits", c.get("n_combo", 0))
                if tp >= 5:
                    rel_icon, rel_label = "ğŸŸ¢", "ä¿¡é ¼åº¦: é«˜ï¼ˆNâ‰¥5ï¼‰"
                elif tp >= 3:
                    rel_icon, rel_label = "ğŸŸ¡", "ä¿¡é ¼åº¦: ä¸­ï¼ˆN=3ã€œ4ï¼‰"
                else:
                    rel_icon, rel_label = "ğŸ”´", "ä¿¡é ¼åº¦: ä½ï¼ˆNâ‰¤2 â€” å‚è€ƒå€¤ï¼‰"
                cond_lines = _combo_cond_lines(c, numbered=True)
                with st.expander(
                    f"{rel_icon} **#{i+1}** â€” è¨“ç·´ç²¾åº¦ **{c['precision']:.0%}**ï¼ˆ{c['lift']:.1f}å€ï¼‰ã€€"
                    f"ã‚«ãƒãƒ¼ç‡: {c['recall']:.0%}",
                    expanded=(i == 0),
                ):
                    st.markdown("**ä»¥ä¸‹ã®æ¡ä»¶ã‚’å…¨ã¦åŒæ™‚ã«æº€ãŸã—ã¦ã„ã‚‹éŠ˜æŸ„:**")
                    for line in cond_lines:
                        st.markdown(line)
                    st.caption(rel_label)

    st.markdown("")

    # ================================================================
    # ãƒ–ãƒ­ãƒƒã‚¯2: åˆå‹•å¾Œã«è²·ã£ãŸã‚‰ä½•%ãƒªã‚¿ãƒ¼ãƒ³ï¼Ÿ
    # ================================================================
    st.markdown(
        '<p style="font-size:14px;font-weight:700;margin:12px 0 8px 0;">'
        'ğŸ’° åˆå‹•å¾Œã®æœ€å¤§åˆ°é”ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆä¿æœ‰ä¸­ã®ãƒ”ãƒ¼ã‚¯æ™‚ç‚¹ï¼‰</p>',
        unsafe_allow_html=True,
    )

    if ret_pairs:
        returns = [r for _, r in ret_pairs]
        n = len(returns)
        mean_ret = sum(returns) / n
        sorted_r = sorted(returns)
        median_ret = sorted_r[n // 2]
        max_ret = max(returns)
        min_ret = min(returns)
        # 60æ—¥å†…ã«ä¸€åº¦ã§ã‚‚+0%ä»¥ä¸Šã«ãªã£ãŸéŠ˜æŸ„ã®å‰²åˆ
        win_rate = sum(1 for r in returns if r > 0) / n

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("å¹³å‡ æœ€å¤§ãƒªã‚¿ãƒ¼ãƒ³", f"{mean_ret:.1%}")
        c2.metric("ä¸­å¤®å€¤ æœ€å¤§ãƒªã‚¿ãƒ¼ãƒ³", f"{median_ret:.1%}")
        c3.metric("æœ€å¤§ / æœ€å°", f"{max_ret:.0%} / {min_ret:.0%}")
        c4.metric("ãƒ—ãƒ©ã‚¹ã«åˆ°é”ã—ãŸå‰²åˆ", f"{win_rate:.0%}")

        st.caption(f"â€» {n}éŠ˜æŸ„ã®åˆå‹•å¾Œ60æ—¥é–“ã§ã®æ ªä¾¡ãƒ”ãƒ¼ã‚¯åˆ°é”ãƒªã‚¿ãƒ¼ãƒ³ã€‚å®Ÿéš›ã®å£²å´ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¯å•ã‚ãªã„ã€‚")

        # éŠ˜æŸ„åˆ¥ãƒªã‚¿ãƒ¼ãƒ³æ£’ã‚°ãƒ©ãƒ•ï¼ˆéŠ˜æŸ„åã‚’å«ã‚ã‚‹ï¼‰
        all_stars = result.get("all_stars", [])
        code_to_name = {str(s["code"]): s.get("name", str(s["code"])) for s in all_stars}

        paired_sorted = sorted(ret_pairs, key=lambda x: x[1], reverse=True)
        bar_x = [f"{code_to_name.get(c, c)}" for c, _ in paired_sorted]
        bar_y = [r * 100 for _, r in paired_sorted]
        bar_colors = ["#D32F2F" if v >= 0 else "#1565C0" for v in bar_y]
        bar_text = [f"{v:.0f}%" for v in bar_y]

        # yaxis range ã«ä½™è£•ã‚’æŒãŸã›ã¦ãƒ†ã‚­ã‚¹ãƒˆåˆ‡ã‚Œã‚’é˜²ã
        y_max = max(bar_y) if bar_y else 0
        y_min = min(bar_y) if bar_y else 0
        y_top = y_max * 1.35 + 10
        y_bot = min(y_min * 1.2 - 5, -5)

        fig = go.Figure(go.Bar(
            x=bar_x,
            y=bar_y,
            marker_color=bar_colors,
            text=bar_text,
            textposition="outside",
            textfont=dict(size=9),
        ))
        fig.add_hline(
            y=mean_ret * 100,
            line_dash="dash", line_color="#FF6F00", line_width=2,
            annotation=dict(text=f"å¹³å‡ {mean_ret:.1%}", font_size=10, font_color="#FF6F00"),
        )
        fig.add_hline(y=0, line_color="#999", line_width=1)
        fig.update_layout(
            height=270,
            margin=dict(l=10, r=10, t=20, b=60),
            yaxis=dict(
                title="æœ€å¤§ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆ%ï¼‰",
                range=[y_bot, y_top],
            ),
            font=dict(size=10),
            xaxis=dict(tickangle=-35),
            showlegend=False,
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("åˆå‹•å¾Œãƒªã‚¿ãƒ¼ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆåˆå‹•æ—¥ãŒç‰¹å®šã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰")


# ---------------------------------------------------------------------------
# çµæœè¡¨ç¤º
# ---------------------------------------------------------------------------
def _display_results(result: dict):
    """Phase 1çµæœã‚’è¡¨ç¤º"""

    star_stocks = result.get("star_stocks", [])
    additional_stars = result.get("additional_stars", [])
    common_features = result.get("common_features", {})
    onset_dates = result.get("onset_dates", {})
    all_stars = result.get("all_stars", [])
    ai_interp = result.get("ai_interpretation", "")
    warnings = result.get("warnings", [])

    for w in warnings:
        st.warning(w)

    # --- ã‚µãƒãƒªãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹ ---
    n_onset = sum(1 for od in onset_dates.values() if od.get("onset_date"))
    best_combos = common_features.get("best_combos", [])

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("å…¥åŠ›ã‚¹ã‚¿ãƒ¼æ ª", f"{len(star_stocks)}ä»¶")
    col2.metric("è¿½åŠ ç™ºè¦‹", f"{len(additional_stars)}ä»¶")
    col3.metric("åˆå‹•ç‰¹å®š", f"{n_onset}/{len(all_stars)}ä»¶")
    col4.metric("ãƒ™ã‚¹ãƒˆã‚³ãƒ³ãƒœ", f"{len(best_combos)}ä»¶")

    # --- ç¢ºç‡ãƒ»ãƒªã‚¿ãƒ¼ãƒ³ã‚µãƒãƒªãƒ¼ï¼ˆæœ€é‡è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼‰ ---
    _display_probability_summary(result)

    # --- AIè§£é‡ˆï¼ˆæŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ï¼‰ ---
    if ai_interp:
        with st.expander("AIè§£é‡ˆï¼ˆã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹ï¼‰", expanded=True):
            normalized = _normalize_ai_headers(ai_interp)
            st.markdown(normalized)

    # --- ã‚¿ãƒ–æ§‹æˆ ---
    tabs = st.tabs([
        "å…±é€šç‰¹å¾´é‡",
        f"ã‚¹ã‚¿ãƒ¼æ ªä¸€è¦§ ({len(all_stars)})",
        "åˆå‹•ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³",
        "å€‹åˆ¥è©³ç´°",
        "çµæœã‚³ãƒ”ãƒ¼",
    ])

    with tabs[0]:
        _display_common_features(common_features)

    with tabs[1]:
        _display_star_list(star_stocks, additional_stars, all_stars, onset_dates)

    with tabs[2]:
        _display_onset_timeline(all_stars, onset_dates)

    with tabs[3]:
        _display_individual_detail(all_stars, onset_dates, common_features)

    with tabs[4]:
        _display_copy_text(result)


def _fmt_val(v: float) -> str:
    """å€¤ã®æ¡ã«å¿œã˜ã¦è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    av = abs(v)
    if av == 0:
        return "0"
    if av >= 100:
        return f"{v:,.0f}"
    if av >= 1:
        return f"{v:.2f}"
    if av >= 0.01:
        return f"{v:.4f}"
    return f"{v:.6f}"


# ç‰¹å¾´é‡ã‚­ãƒ¼ â†’ é–¾å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåŒºåˆ†
_FEAT_PCT = {
    # ãƒªã‚¿ãƒ¼ãƒ³ãƒ»é¨°è½ç‡ç³»ï¼ˆÃ— 100 ã—ã¦ %è¡¨ç¤ºï¼‰
    "ret_5d", "ret_20d", "up_days_ratio_10d", "quiet_accum_rate_20d",
    "higher_lows_slope_10d", "range_position_20d",
    "sector_rel_ret_10d", "ma5_ma20_gap", "price_vs_ma20_pct",
    "ma_deviation_25d", "ma_deviation_75d",
    "spread_proxy_5d", "max_gap_up_5d", "gap_frequency_20d",
    "higher_highs_ratio_10d", "proximity_52w_high",
    "margin_buy_change_pct", "margin_ratio_change_pct",
    "bb_width_pctile_60d", "up_volume_ratio_10d",
}
_FEAT_RATIO = {
    # å€ç‡ç³»ï¼ˆXå€ä»¥ä¸Šï¼‰
    "vol_ratio_5d_20d", "vol_ratio_5d_60d", "vol_acceleration",
    "atr_ratio_5d_20d", "intraday_range_ratio_5d", "realized_vol_5d_vs_20d",
    "topix_beta_20d", "residual_vol_ratio", "vol_vs_market_vol",
    "margin_ratio", "margin_buy_vol_ratio", "turnover_change_10d_20d",
    "obv_slope_10d",
}
_FEAT_DAYS = {
    # æ—¥æ•°ç³»ï¼ˆXæ—¥ä»¥ä¸Šï¼‰
    "vol_surge_count_10d", "consecutive_up_days", "margin_buy_turnover_days",
}


def _fmt_threshold(feat_key: str, threshold: float) -> str:
    """é–¾å€¤ã‚’äººé–“ãŒèª­ã‚ã‚‹å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    sign = "+" if threshold > 0 else ""
    if feat_key in _FEAT_PCT:
        pct = threshold * 100
        sign = "+" if pct >= 0 else ""
        return f"{sign}{pct:.1f}%ä»¥ä¸Š"
    elif feat_key in _FEAT_DAYS:
        return f"{int(round(threshold))}æ—¥ä»¥ä¸Š"
    elif feat_key in _FEAT_RATIO:
        return f"{threshold:.2f}å€ä»¥ä¸Š"
    else:
        # ãã®ä»–ï¼ˆç”Ÿã®å€¤ï¼‰
        if abs(threshold) < 10:
            return f"{sign}{threshold:.3f}ä»¥ä¸Š"
        return f"{sign}{threshold:.1f}ä»¥ä¸Š"


def _combo_cond_lines(c: dict, numbered: bool = False) -> list[str]:
    """ã‚³ãƒ³ãƒœã®å„æ¡ä»¶ã‚’ã€Œèª¬æ˜ ãŒ é–¾å€¤ä»¥ä¸Šã€ã®å½¢å¼ã§åˆ—æŒ™ã—ã¦è¿”ã™"""
    features = c.get("features", [])
    features_jp = c.get("features_jp", features)
    thresholds = c.get("thresholds", [0.0] * len(features))
    lines = []
    for idx, (feat_key, feat_label, th) in enumerate(zip(features, features_jp, thresholds)):
        desc = WIDE_FEATURE_DESCRIPTIONS_JP.get(feat_key, feat_label)
        th_str = _fmt_threshold(feat_key, th)
        prefix = f"{idx+1}. " if numbered else "  âœ… "
        lines.append(f"{prefix}**{feat_label}**ï¼ˆ{desc}ï¼‰ãŒ **{th_str}**")
    return lines


def _display_common_features(common_features: dict):
    """å…±é€šç‰¹å¾´é‡ã®è¡¨ç¤º â€” ã‚¹ã‚¿ãƒ¼æ ª vs éã‚¹ã‚¿ãƒ¼æ ªã®æ¯”è¼ƒã‚’é‡è¦–"""

    if common_features.get("error"):
        st.warning(common_features["error"])
        return

    signals = common_features.get("signals", [])
    best_combos = common_features.get("best_combos", [])
    combo_signals = common_features.get("combo_signals", [])
    base_rate = common_features.get("base_rate", 0)
    n_star = common_features.get("n_star", 0)
    n_non_star = common_features.get("n_non_star", 0)

    useful_signals = [s for s in signals if s.get("verdict") != "meaningless"][:12]
    if not useful_signals:
        st.info("æœ‰æ„ãªç‰¹å¾´é‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    # --- Cohen's dè¨ˆç®—ï¼ˆstdãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰ ---
    has_std = any(s.get("pos_std") for s in useful_signals)
    if has_std:
        for s in useful_signals:
            pos_std = s.get("pos_std") or 0.01
            neg_std = s.get("neg_std") or 0.01
            pooled = max(np.sqrt((pos_std**2 + neg_std**2) / 2), 0.0001)
            s["cohens_d"] = round((s["pos_mean"] - s["neg_mean"]) / pooled, 2)
        sorted_by_d = sorted(useful_signals, key=lambda s: abs(s.get("cohens_d", 0)), reverse=True)
    else:
        # stdãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆæ—§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰â†’ J-staté †
        sorted_by_d = sorted(useful_signals, key=lambda s: s["j_stat"], reverse=True)

    # ================================================================
    # Section 1: Small multiples â€” ã‚¹ã‚¿ãƒ¼æ ª vs éã‚¹ã‚¿ãƒ¼æ ª ç›´æ¥æ¯”è¼ƒ
    # ================================================================
    _section("ã‚¹ã‚¿ãƒ¼æ ª vs éã‚¹ã‚¿ãƒ¼æ ª â€” ç‰¹å¾´é‡ã®ç›´æ¥æ¯”è¼ƒ")
    st.caption(
        f"ã‚¹ã‚¿ãƒ¼æ ª {n_star}ä»¶ vs ãƒ©ãƒ³ãƒ€ãƒ éã‚¹ã‚¿ãƒ¼æ ª {n_non_star}ä»¶ã€‚"
        f"å„ã‚°ãƒ©ãƒ•ã¯ã€Œã‚¹ã‚¿ãƒ¼æ ªã¯ã“ã®æŒ‡æ¨™ãŒéã‚¹ã‚¿ãƒ¼æ ªã®ä½•å€ã‹ã€ã‚’ç¤ºã™ã€‚"
        f"å€ç‡ãŒé«˜ã„ã»ã©ã‚¹ã‚¿ãƒ¼æ ªã«ç‰¹æœ‰ã®çŠ¶æ…‹ã€‚"
    )

    # Top 6 features in 3-column gridï¼ˆå€ç‡è¡¨ç¤ºã«å¤‰æ›´ï¼‰
    top_for_chart = sorted_by_d[:6]
    cols = st.columns(3)
    for i, s in enumerate(top_for_chart):
        with cols[i % 3]:
            pos_m = s["pos_mean"]
            neg_m = s["neg_mean"]
            # å€ç‡è¨ˆç®—ï¼ˆåˆ†æ¯0å¯¾ç­–ï¼‰
            ratio = pos_m / neg_m if abs(neg_m) > 1e-9 else float("inf")

            feat_desc = WIDE_FEATURE_DESCRIPTIONS_JP.get(s["feature"], s.get("feature_jp", s["feature"]))
            # èª¬æ˜æ–‡ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã«ä½¿ç”¨ï¼ˆ40æ–‡å­—ã¾ã§ï¼‰
            desc_short = feat_desc[:38] + "â€¦" if len(feat_desc) > 38 else feat_desc

            # å€ç‡ã‚’æ£’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤º
            bar_vals = [1.0, ratio if ratio != float("inf") else 0]
            bar_labels = ["å¸‚å ´å¹³å‡ï¼ˆåŸºæº–ï¼‰", f"ã‚¹ã‚¿ãƒ¼æ ª {ratio:.1f}å€" if ratio != float("inf") else "ã‚¹ã‚¿ãƒ¼æ ª"]
            bar_colors = ["#9E9E9E", "#D32F2F"]
            bar_texts = ["åŸºæº– 1.0å€", f"+{ratio:.1f}å€" if ratio > 0 else f"{ratio:.1f}å€"]

            # yaxis range â€” textposition="outside" ã®ã‚¯ãƒªãƒƒãƒ—å¯¾ç­–
            y_top = max(bar_vals) * 1.5 if max(bar_vals) > 0 else 2.0

            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=bar_labels,
                y=bar_vals,
                marker_color=bar_colors,
                text=bar_texts,
                textposition="outside",
                textfont=dict(size=11, color=["#555", "#C62828"]),
                width=0.55,
            ))
            # åŸºæº–ãƒ©ã‚¤ãƒ³
            fig.add_hline(y=1.0, line_dash="dash", line_color="#999", line_width=1)
            ratio_label = f"{ratio:.1f}å€" if ratio != float("inf") else "âˆ"
            fig.update_layout(
                title=dict(
                    text=f"<b>{desc_short}</b><br><sup>ã‚¹ã‚¿ãƒ¼æ ªã¯å¸‚å ´å¹³å‡ã® {ratio_label}</sup>",
                    font_size=11,
                ),
                height=280,
                margin=dict(l=20, r=10, t=75, b=15),
                showlegend=False,
                font=dict(size=10),
                yaxis=dict(
                    title="å¸‚å ´å¹³å‡æ¯”ï¼ˆå€ï¼‰",
                    range=[0, y_top],
                    zeroline=True, zerolinecolor="#E0E0E0",
                ),
            )
            st.plotly_chart(fig, use_container_width=True)

    # ================================================================
    # Section 2: ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒãƒ£ãƒ¼ãƒˆï¼ˆYouden's J â€” åˆ¤åˆ¥åŠ›ï¼‰
    # ================================================================
    _section("ç‰¹å¾´é‡ãƒ©ãƒ³ã‚­ãƒ³ã‚° â€” ã‚¹ã‚¿ãƒ¼æ ªã‚’è­˜åˆ¥ã™ã‚‹åŠ›ï¼ˆä¸Šä½10ä»¶ï¼‰")
    st.caption(
        "Youden's J = ï¼ˆã‚¹ã‚¿ãƒ¼æ ªã§ã“ã®æ¡ä»¶ã‚’æº€ãŸã—ãŸå‰²åˆï¼‰-ï¼ˆéã‚¹ã‚¿ãƒ¼æ ªã§ã“ã®æ¡ä»¶ã‚’æº€ãŸã—ãŸå‰²åˆï¼‰ã€‚"
        "J=1.0 ãªã‚‰å®Œç’§ã«åŒºåˆ¥ã§ãã€J=0.0 ãªã‚‰æ„å‘³ãªã—ã€‚"
        "å€¤ãŒå¤§ãã„ã»ã©ã€Œã‚¹ã‚¿ãƒ¼æ ªã«ç‰¹æœ‰ã®çŠ¶æ…‹ã€ã‚’è¡¨ã™ç‰¹å¾´é‡ã§ã™ã€‚"
    )

    # J-staté †ã«ã‚½ãƒ¼ãƒˆï¼ˆä¸Šä½10ä»¶ï¼‰
    top10_j = sorted(useful_signals, key=lambda s: s["j_stat"], reverse=True)[:10]
    top10_j_rev = list(reversed(top10_j))

    chart_names = [s.get("feature_jp", s["feature"]) for s in top10_j_rev]
    chart_vals = [s["j_stat"] for s in top10_j_rev]
    chart_labels = [
        f"J={v:.2f} ({WIDE_FEATURE_DESCRIPTIONS_JP.get(s['feature'], '')[:12]}â€¦)"
        if len(WIDE_FEATURE_DESCRIPTIONS_JP.get(s['feature'], '')) > 12
        else f"J={v:.2f}"
        for s, v in zip(top10_j_rev, chart_vals)
    ]
    chart_colors = [
        "#C62828" if s["verdict"] == "strong" else
        "#EF6C00" if s["verdict"] == "weak_useful" else "#9E9E9E"
        for s in top10_j_rev
    ]

    fig_rank = go.Figure(go.Bar(
        x=chart_vals, y=chart_names, orientation="h",
        marker_color=chart_colors,
        text=[f"J={v:.2f}" for v in chart_vals],
        textposition="auto",
        textfont=dict(size=10),
        customdata=[
            [WIDE_FEATURE_DESCRIPTIONS_JP.get(s["feature"], ""), s["pos_mean"], s["neg_mean"]]
            for s in top10_j_rev
        ],
        hovertemplate=(
            "<b>%{y}</b><br>"
            "èª¬æ˜: %{customdata[0]}<br>"
            "Jå€¤: %{x:.3f}<br>"
            "ã‚¹ã‚¿ãƒ¼æ ªå¹³å‡: %{customdata[1]:.4f}<br>"
            "å¸‚å ´å¹³å‡: %{customdata[2]:.4f}<extra></extra>"
        ),
    ))
    fig_rank.add_vline(x=0.5, line_dash="dot", line_color="#999",
                       annotation_text="ä¸­ç¨‹åº¦", annotation_position="top right",
                       annotation_font_size=9)
    fig_rank.update_layout(
        height=max(220, len(top10_j) * 30 + 50),
        margin=dict(l=220, r=60, t=20, b=20),
        xaxis=dict(title="åˆ¤åˆ¥åŠ› Youden's Jï¼ˆ0.0ã€œ1.0ï¼‰", range=[0, 1.05]),
        font=dict(size=11),
    )
    st.plotly_chart(fig_rank, use_container_width=True)

    # å…¨ç‰¹å¾´é‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰
    with st.expander(f"å…¨ç‰¹å¾´é‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆ{len(useful_signals)}ä»¶ï¼‰", expanded=False):
        rank_rows = []
        for rank_i, s in enumerate(sorted(useful_signals, key=lambda s: s["j_stat"], reverse=True), 1):
            pos_m = s["pos_mean"]
            neg_m = s["neg_mean"]
            ratio_str = f"{pos_m/neg_m:.1f}å€" if abs(neg_m) > 1e-9 and neg_m > 0 else "âˆ’"
            rank_rows.append({
                "é †ä½": rank_i,
                "ç‰¹å¾´é‡": s.get("feature_jp", s["feature"]),
                "èª¬æ˜": WIDE_FEATURE_DESCRIPTIONS_JP.get(s["feature"], ""),
                "Jå€¤": f"{s['j_stat']:.3f}",
                "ã‚¹ã‚¿ãƒ¼æ ªå¹³å‡": _fmt_val(pos_m),
                "å¸‚å ´å¹³å‡": _fmt_val(neg_m),
                "å€ç‡": ratio_str,
                "åˆ¤å®š": s.get("verdict", ""),
            })
        st.dataframe(pd.DataFrame(rank_rows), use_container_width=True, hide_index=True)

    # ================================================================
    # Section 3: è©³ç´°æ¯”è¼ƒãƒ†ãƒ¼ãƒ–ãƒ«
    # ================================================================
    with st.expander("è©³ç´°æ¯”è¼ƒãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå…¨ç‰¹å¾´é‡ï¼‰", expanded=False):
        rows = []
        for s in sorted_by_d:
            pos_m = s["pos_mean"]
            neg_m = s["neg_mean"]
            row = {
                "ç‰¹å¾´é‡": s.get("feature_jp", s["feature"]),
                "ã‚¹ã‚¿ãƒ¼æ ª": _fmt_val(pos_m),
                "éã‚¹ã‚¿ãƒ¼æ ª": _fmt_val(neg_m),
                "å·®": f"{pos_m - neg_m:+.4f}",
            }
            if has_std:
                row["åŠ¹æœé‡(d)"] = f"{s.get('cohens_d', 0):.1f}"
            row.update({
                "é–¾å€¤": f">={_fmt_val(s['threshold'])}",
                "Jå€¤": f"{s['j_stat']:.3f}",
                "Lift": f"{s['lift']:.1f}x",
                "ç²¾åº¦": f"{s['precision']:.0%}",
                "å†ç¾ç‡": f"{s['recall']:.0%}",
            })
            rows.append(row)
        df = pd.DataFrame(rows)
        st.dataframe(df, use_container_width=True, hide_index=True)

    # ================================================================
    # Section 4: ãƒ™ã‚¹ãƒˆç‰¹å¾´é‡ã‚³ãƒ³ãƒœ
    # ================================================================
    _section("ãƒ™ã‚¹ãƒˆç‰¹å¾´é‡ã‚³ãƒ³ãƒœ â€” è¤‡æ•°æ¡ä»¶ã‚’åŒæ™‚ã«æº€ãŸã™éŠ˜æŸ„ã®çµã‚Šè¾¼ã¿")
    if best_combos:
        base_rate_u = common_features.get("base_rate_universe", base_rate)
        n_univ = common_features.get("n_universe", 0)

        # æ¯é›†å›£ã§æ¡ä»¶åˆè‡´0ä»¶ï¼ˆéå­¦ç¿’ï¼‰ã®ã‚³ãƒ³ãƒœã‚’åˆ†é›¢
        valid_bc = [c for c in best_combos[:5] if c.get("universe_n_hits", 0) > 0 or c.get("universe_precision") is None]
        overfit_bc = [c for c in best_combos[:5] if c.get("universe_precision") is not None and c.get("universe_n_hits", 0) == 0]

        for i, c in enumerate(valid_bc):
            u_prec = c.get("universe_precision")
            u_hits = c.get("universe_n_hits", 0)
            u_stars = c.get("universe_n_stars", 0)
            cond_lines = _combo_cond_lines(c, numbered=True)

            if u_prec is not None and n_univ > 0:
                u_lift = u_prec / base_rate_u if base_rate_u > 0 else 0
                header = (
                    f"**#{i+1}**  ã‚¹ã‚¿ãƒ¼æ ªç¢ºç‡ **{u_prec:.1%}**ï¼ˆ{u_lift:.1f}å€ï¼‰ã€€"
                    f"åˆè‡´: {u_hits}ä»¶ / ã‚¹ã‚¿ãƒ¼æ ª: {u_stars}ä»¶ã€€ã‚«ãƒãƒ¼ç‡: {c['recall']:.0%}"
                )
            else:
                header = (
                    f"**#{i+1}**  ç²¾åº¦ **{c['precision']:.0%}**ï¼ˆ{c['lift']:.1f}å€ï¼‰ã€€"
                    f"ã‚«ãƒãƒ¼ç‡: {c['recall']:.0%}"
                )

            with st.expander(header, expanded=(i == 0)):
                st.markdown("**ä»¥ä¸‹ã®æ¡ä»¶ã‚’å…¨ã¦åŒæ™‚ã«æº€ãŸã—ã¦ã„ã‚‹éŠ˜æŸ„:**")
                for line in cond_lines:
                    st.markdown(line)

        if overfit_bc:
            with st.expander(f"âš ï¸ éå­¦ç¿’ã‚³ãƒ³ãƒœï¼ˆæ¯é›†å›£ã§0ä»¶åˆè‡´ï¼‰ {len(overfit_bc)}ä»¶", expanded=False):
                st.warning("è¨“ç·´ãƒ‡ãƒ¼ã‚¿å†…ã§ã¯é«˜ç²¾åº¦ã§ã—ãŸãŒã€å…¨éŠ˜æŸ„Ã—è¤‡æ•°æ™‚ç‚¹ã®ã‚¹ã‚­ãƒ£ãƒ³ã§ä¸€åº¦ã‚‚åˆè‡´ã—ã¾ã›ã‚“ã§ã—ãŸã€‚æ¡ä»¶ãŒå³ã—ã™ãã‚‹ãŸã‚å®Ÿç”¨å¤–ã§ã™ã€‚")
                for i, c in enumerate(overfit_bc):
                    cond_lines = _combo_cond_lines(c, numbered=True)
                    with st.expander(f"éå­¦ç¿’ #{i+1}  è¨“ç·´ç²¾åº¦={c['precision']:.0%}ï¼ˆå‚è€ƒã®ã¿ï¼‰", expanded=False):
                        for line in cond_lines:
                            st.markdown(line)
    elif combo_signals:
        st.info(
            "ç²¾åº¦ãƒ»å†ç¾ç‡ã®é–¾å€¤ã‚’æº€ãŸã™ã‚³ãƒ³ãƒœãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
            "ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œã‚³ãƒ³ãƒœæœ€ä½ç²¾åº¦ã€ã€Œã‚³ãƒ³ãƒœæœ€ä½å†ç¾ç‡ã€ã‚’ä¸‹ã’ã¦ã¿ã¦ãã ã•ã„"
        )
        with st.expander("å‚è€ƒ: ä¸Šä½ã‚³ãƒ³ãƒœï¼ˆé–¾å€¤æœªé”ï¼‰"):
            rows = []
            for c in combo_signals[:10]:
                names = " AND ".join(c.get("features_jp", c["features"]))
                rows.append({
                    "ã‚³ãƒ³ãƒœ": names,
                    "ç²¾åº¦": f"{c['precision']:.0%}",
                    "å†ç¾ç‡": f"{c['recall']:.0%}",
                    "Lift": f"{c['lift']:.1f}x",
                })
            st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
    else:
        st.info("ç‰¹å¾´é‡ã‚³ãƒ³ãƒœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


def _display_star_list(
    star_stocks: list, additional_stars: list,
    all_stars: list, onset_dates: dict,
):
    """å…¨ã‚¹ã‚¿ãƒ¼æ ªã‚’å…¥åŠ›/ç™ºè¦‹ã®åŒºåˆ¥ä»˜ãã§ä¸€è¦§è¡¨ç¤º"""

    st.markdown(
        f'{TAG_INPUT} ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸã‚¹ã‚¿ãƒ¼æ ªã€€'
        f'{TAG_FOUND} å…±é€šç‰¹å¾´é‡ã‚³ãƒ³ãƒœæ¡ä»¶ã§è‡ªå‹•ç™ºè¦‹ã•ã‚ŒãŸéŠ˜æŸ„',
        unsafe_allow_html=True,
    )
    st.caption(
        "60æ—¥å¾Œãƒªã‚¿ãƒ¼ãƒ³(å‚è€ƒ): åˆå‹•ã‹ã‚‰60æ—¥å¾Œæ™‚ç‚¹ã§ã®æ ªä¾¡å¤‰åŒ–ç‡ã€€ï½œã€€"
        "æœ€å¤§ãƒªã‚¿ãƒ¼ãƒ³(æœŸé–“æœ«ã¾ã§): åˆå‹•å¾Œã€œåˆ†ææœŸé–“çµ‚äº†ã¾ã§ã®ãƒ”ãƒ¼ã‚¯åˆ°é”ãƒªã‚¿ãƒ¼ãƒ³ã€€ï½œã€€"
        "æœ€å¤§DD: åˆå‹•å¾Œã€œæœŸé–“æœ«ã§ã®ãƒ”ãƒ¼ã‚¯ã‹ã‚‰ã®æœ€å¤§ä¸‹è½ç‡ï¼ˆãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ï¼‰"
    )

    rows = []
    for star in all_stars:
        code = str(star["code"])
        od = onset_dates.get(code, {})
        is_input = star.get("source") == "user"
        has_onset = bool(od.get("onset_date"))
        rows.append({
            "ç¨®åˆ¥": "å…¥åŠ›" if is_input else "ç™ºè¦‹",
            "ã‚³ãƒ¼ãƒ‰": code,
            "éŠ˜æŸ„å": star.get("name", ""),
            "ã‚»ã‚¯ã‚¿ãƒ¼": star.get("sector", star.get("sector_17_name", "")),
            "è¶…éãƒªã‚¿ãƒ¼ãƒ³": f"{star.get('excess_return', 0):.1%}"
                if star.get("excess_return") is not None else "-",
            "åˆå‹•æ—¥": od.get("onset_date", "-"),
            "ã‚·ã‚°ãƒŠãƒ«æ•°": od.get("score", 0) if has_onset else "-",
            "60æ—¥å¾Œãƒªã‚¿ãƒ¼ãƒ³(å‚è€ƒ)": f"{od['fwd_return_60d']:.1%}" if has_onset and od.get("fwd_return_60d") is not None else "-",
            "æœ€å¤§ãƒªã‚¿ãƒ¼ãƒ³(æœŸé–“æœ«ã¾ã§)": (
                f"{(od.get('max_return') or od.get('max_return_60d')):.1%}"
                if has_onset and (od.get("max_return") or od.get("max_return_60d")) is not None else "-"
            ),
            "æœ€å¤§DD": (
                f"{(od.get('max_drawdown') or od.get('max_drawdown_60d')):.1%}"
                if has_onset and (od.get("max_drawdown") or od.get("max_drawdown_60d")) is not None else "-"
            ),
        })

    if rows:
        df = pd.DataFrame(rows)
        st.dataframe(
            df.style.apply(
                lambda row: [
                    "background-color: #E3F2FD" if row["ç¨®åˆ¥"] == "å…¥åŠ›"
                    else "background-color: #FFF3E0"
                ] * len(row),
                axis=1,
            ),
            use_container_width=True, hide_index=True,
        )


def _fmt_signal_with_qty(sig_key: str, sig_qty: dict) -> str:
    """ã‚·ã‚°ãƒŠãƒ«åã«æ•°å€¤æƒ…å ±ã‚’ä»˜åŠ ï¼ˆä¾‹: å‡ºæ¥é«˜æ€¥å¢—ï¼ˆå¹³å‡ã®3.2å€ï¼‰ï¼‰"""
    base = SIGNAL_JP_SHORT.get(sig_key, sig_key)
    if sig_key not in sig_qty:
        return base
    qty = sig_qty[sig_key]
    if sig_key == "volume_surge":
        return f"{base}ï¼ˆå¹³å‡ã®{qty}å€ï¼‰"
    elif sig_key == "higher_lows":
        sign = "+" if qty >= 0 else ""
        return f"{base}ï¼ˆ10æ—¥ã§{sign}{qty}%ä¸Šæ˜‡ï¼‰"
    elif sig_key == "range_breakout":
        sign = "+" if qty >= 0 else ""
        return f"{base}ï¼ˆ20æ—¥é«˜å€¤ã‚’{sign}{qty}%çªç ´ï¼‰"
    elif sig_key == "up_volume_dominance":
        return f"{base}ï¼ˆè²·ã„æ—¥ã®å‡ºæ¥é«˜{qty:.0f}%ï¼‰"
    elif sig_key == "obv_breakout":
        sign = "+" if qty >= 0 else ""
        return f"{base}ï¼ˆ10æ—¥ã§{sign}{qty}%ä¸Šæ˜‡ï¼‰"
    elif sig_key == "quiet_accumulation":
        return f"{base}ï¼ˆ5æ—¥å¹³å‡å‡ºæ¥é«˜ã¯20æ—¥å¹³å‡ã®{qty}å€ï¼‰"
    elif sig_key == "ma_crossover":
        sign = "+" if qty >= 0 else ""
        return f"{base}ï¼ˆçŸ­æœŸç·šãŒä¸­æœŸç·šã‚’{sign}{qty}%ä¸Šå›ã‚‹ï¼‰"
    return base


def _display_onset_timeline(all_stars: list, onset_dates: dict):
    """åˆå‹•ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã®è¡¨ç¤º"""

    rows = []
    for star in all_stars:
        code = str(star["code"])
        od = onset_dates.get(code, {})
        is_input = star.get("source") == "user"
        sig_qty = od.get("signal_quantities", {})
        sigs_jp = "ã€".join(
            _fmt_signal_with_qty(s, sig_qty) for s in od.get("signals", [])
        )
        # max_returnï¼ˆæ–°ï¼‰ > max_return_60dï¼ˆæ—§ï¼‰ > fwd_return_60d ã®å„ªå…ˆé †
        max_ret = od.get("max_return") or od.get("max_return_60d") or od.get("fwd_return_60d")
        rows.append({
            "ç¨®åˆ¥": "å…¥åŠ›" if is_input else "ç™ºè¦‹",
            "ã‚³ãƒ¼ãƒ‰": code,
            "éŠ˜æŸ„å": star.get("name", ""),
            "åˆå‹•æ—¥": od.get("onset_date", "-"),
            "ã‚·ã‚°ãƒŠãƒ«æ•°": od.get("score", 0),
            "ç™ºç«ã‚·ã‚°ãƒŠãƒ«": sigs_jp,
            "æœ€å¤§ãƒªã‚¿ãƒ¼ãƒ³(æœŸé–“æœ«)": f"{max_ret:.1%}" if od.get("onset_date") and max_ret is not None else "-",
        })

    if rows:
        df = pd.DataFrame(rows)
        df_sorted = df.sort_values("åˆå‹•æ—¥", ascending=True)
        st.dataframe(
            df_sorted.style.apply(
                lambda row: [
                    "background-color: #E3F2FD" if row["ç¨®åˆ¥"] == "å…¥åŠ›"
                    else "background-color: #FFF3E0"
                ] * len(row),
                axis=1,
            ),
            use_container_width=True, hide_index=True,
        )

    # ã‚·ã‚°ãƒŠãƒ«é »åº¦
    signal_counts = {}
    for od in onset_dates.values():
        for sig in od.get("signals", []):
            signal_counts[sig] = signal_counts.get(sig, 0) + 1

    if signal_counts:
        _section("åˆå‹•ã‚·ã‚°ãƒŠãƒ«é »åº¦")
        sorted_signals = sorted(signal_counts.items(), key=lambda x: -x[1])
        n_total = len(onset_dates)
        # ã‚·ã‚°ãƒŠãƒ«åã‚’æ—¥æœ¬èªã«å¤‰æ›ï¼ˆçŸ­ç¸®åï¼‹è‹±èªåï¼‰
        sig_labels = [
            f"{SIGNAL_JP_SHORT.get(s[0], s[0])}"
            for s in sorted_signals
        ]
        fig = go.Figure(go.Bar(
            x=[s[1] for s in sorted_signals],
            y=sig_labels,
            orientation="h",
            marker_color="#1E88E5",
            text=[f"{s[1]}/{n_total}" for s in sorted_signals],
            textposition="auto",
        ))
        fig.update_layout(
            height=max(200, len(sorted_signals) * 28 + 40),
            margin=dict(l=200, r=40, t=10, b=20),
            xaxis_title="ç™ºç«å›æ•°",
            font=dict(size=11),
        )
        st.plotly_chart(fig, use_container_width=True)


def _display_individual_detail(all_stars: list, onset_dates: dict, common_features: dict):
    """å€‹åˆ¥éŠ˜æŸ„ã®è©³ç´°è¡¨ç¤º"""

    if not all_stars:
        st.info("è¡¨ç¤ºã™ã‚‹éŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    options = [
        f"{s['code']} {s.get('name', '')} ({'å…¥åŠ›' if s.get('source') == 'user' else 'ç™ºè¦‹'})"
        for s in all_stars
    ]
    selected = st.selectbox("éŠ˜æŸ„ã‚’é¸æŠ", options)
    if not selected:
        return

    code = selected.split(" ")[0]
    star = next((s for s in all_stars if str(s["code"]) == code), None)
    if star is None:
        return

    od = onset_dates.get(code, {})
    is_input = star.get("source") == "user"
    tag_html = TAG_INPUT if is_input else TAG_FOUND

    st.markdown(
        f'{tag_html} **{code} {star.get("name", "")}**'
        f' â€” {star.get("sector", star.get("sector_17_name", ""))}',
        unsafe_allow_html=True,
    )

    col1, col2, col3 = st.columns(3)
    if star.get("total_return") is not None:
        col1.metric("æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³", f"{star['total_return']:.1%}")
    if star.get("excess_return") is not None:
        col2.metric("è¶…éãƒªã‚¿ãƒ¼ãƒ³", f"{star['excess_return']:.1%}")
    if od.get("onset_date"):
        col3.metric("åˆå‹•æ—¥", od["onset_date"])

    if od.get("onset_date"):
        _section("åˆå‹•ã‚·ã‚°ãƒŠãƒ«")
        sig_qty = od.get("signal_quantities", {})
        sigs_detail = []
        for s in od.get("signals", []):
            with_qty = _fmt_signal_with_qty(s, sig_qty)
            full_desc = ONSET_SIGNAL_NAMES_JP.get(s, s)
            sigs_detail.append(f"{with_qty}ï¼ˆ{full_desc}ï¼‰")
        max_ret = od.get("max_return") or od.get("max_return_60d") or od.get("fwd_return_60d")
        sig_text = f"ã‚·ã‚°ãƒŠãƒ«ã‚¹ã‚³ã‚¢: **{od['score']}/10** ï½œ "
        if max_ret is not None:
            sig_text += f"æœ€å¤§åˆ°é”ãƒªã‚¿ãƒ¼ãƒ³: **{max_ret:.1%}** ï½œ "
        sig_text += "ç™ºç«: " + "ã€".join(sigs_detail)
        st.markdown(sig_text)
    else:
        st.info("åˆå‹•æ—¥ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ")

    if star.get("matched_combo"):
        _section("ç™ºè¦‹æ¡ä»¶ï¼ˆåˆè‡´ã‚³ãƒ³ãƒœï¼‰")
        combo = star["matched_combo"]
        parts = []
        for fn, val, th in zip(
            combo.get("features", []),
            combo.get("values", []),
            combo.get("thresholds", []),
        ):
            parts.append(f"`{fn}` = {val:.4f} (>={th:.4f})")
        st.markdown(" AND ".join(parts))


def _display_copy_text(result: dict):
    """çµæœã‚’ä¸€æ‹¬ã‚³ãƒ”ãƒ¼å¯èƒ½ãªãƒ†ã‚­ã‚¹ãƒˆã§è¡¨ç¤º"""
    text = _build_result_text(result)
    st.text_area(
        "ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¨é¸æŠã—ã¦ã‚³ãƒ”ãƒ¼ã§ãã¾ã™ï¼ˆCtrl+A â†’ Ctrl+Cï¼‰",
        value=text,
        height=500,
    )


# ---------------------------------------------------------------------------
if __name__ == "__main__" or True:
    main()
