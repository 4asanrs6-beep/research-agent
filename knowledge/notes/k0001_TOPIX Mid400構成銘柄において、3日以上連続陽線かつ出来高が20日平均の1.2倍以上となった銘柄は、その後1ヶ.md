# TOPIX Mid400構成銘柄において、3日以上連続陽線かつ出来高が20日平均の1.2倍以上となった銘柄は、その後1ヶ月間でTOPIXを上回る超過リターンを示す

- **Knowledge ID**: 1
- **Run ID**: 11
- **判定**: needs_review
- **作成日**: 2026-02-23 09:11:15
- **タグ**: モメンタム, 出来高, 連続陽線, イベントスタディ, TOPIX_Mid400, 頑健性不足, 要追加検証

## 分析条件

- **対象**: TOPIX Mid400構成銘柄（時価総額上位101位〜500位相当、約400銘柄）
- **期間**: 2025-02-01 ~ 2026-02-23
- **アプローチ**: イベントスタディ形式で、シグナル発生日をイベント日とし、その後1ヶ月間の累積超過リターン（対TOPIX）を計測・統計検定する。全シグナルイベントを集約して平均的な超過リターンの有意性を評価し、併せてリスク調整後指標やサブグループ分析を行う。
  1. ステップ1: J-Quants APIから上場銘柄一覧を取得し、TOPIX Mid400構成銘柄のユニバースを確定する。期間中の構成銘柄変更がある場合はポイントインタイムベースで管理し、サバイバーシップバイアスを回避する。
  2. ステップ2: ユニバース全銘柄の日足OHLCVデータ（調整後価格ベース）を取得し、各営業日について陽線判定（調整後終値 > 調整後始値）を行う。
  3. ステップ3: 各銘柄・各営業日について出来高の直近20営業日単純移動平均を算出し、当日出来高が20日平均の1.2倍以上かを判定するフラグを作成する。
  4. ステップ4: シグナル条件を定義 — 当日を含め直近3営業日以上連続で陽線であり、かつ当日の出来高が20日平均の1.2倍以上。条件を満たした日をシグナル発生日とする。同一銘柄で連続してシグナルが発生した場合は、最初のシグナル日のみを採用し、以降1ヶ月間は同一銘柄の新規シグナルを抑制する（重複回避）。
  5. ステップ5: TOPIX日次リターンを算出し、各シグナル発生日の翌営業日から1ヶ月間（約21営業日）の銘柄累積リターンおよびTOPIX累積リターンを計算。超過リターン（銘柄リターン − TOPIXリターン）を算出する。
  6. ステップ6: 全シグナルイベントの超過リターンの記述統計（平均、中央値、標準偏差、最大、最小、正の割合）を算出する。
  7. ステップ7: 超過リターンの平均がゼロと有意に異なるかを統計検定する。コントロールグループとして、シグナル未発生の同ユニバース銘柄のランダム1ヶ月リターンとの比較も行う。
  8. ステップ8: ロバストネスチェックとして、連続陽線日数の閾値（3日、4日、5日）および出来高倍率の閾値（1.2倍、1.5倍、2.0倍）をパラメータとした感度分析を実施する。
  9. ステップ9: セクター別・月別のサブグループ分析を行い、シグナルの有効性に偏りがないかを確認する。
  10. ステップ10: 結果を総合し、仮説の採否を判断する。

## 統計結果

| 指標 | 値 |
|------|-----|
| p値 | 0.0248 |
| t統計量 | 2.262 |
| Cohen's d | 0.158 |
| 条件群平均 | 1.2377% |
| 基準群平均 | 0.3773% |
| 条件群勝率 | 51.7% |
| 基準群勝率 | 49.3% |
| 条件群N | 205 |
| 基準群N | 300 |
| 有意性 | 有意 |

## バックテスト結果

| 指標 | 値 |
|------|-----|
| 累計リターン | 41.10% |
| 年率リターン | 40.15% |
| シャープ比 | 2.00 |
| 最大DD | -19.93% |
| 勝率 | 65.4% |
| 取引回数 | 205 |
| BM累計リターン | 40.00% |

## 解釈

一標本t検定では名目上p=0.025と有意だが、Bonferroni補正後（p=0.223）、ノンパラメトリック検定（Wilcoxon p=0.076）、ベースラインとの二標本比較（p=0.226）のいずれでも有意性が消失する。効果量もCohen's d=0.158と小さく基準未達であり、感度分析でもパラメータを厳格化すると効果が消失するため、現時点では仮説の頑健な支持は得られていない。

**判断理由:**
- Bonferroni補正後のp値が0.223となり、多重比較を考慮すると統計的有意性が消失する。9条件の感度分析でBonferroni補正を生き残る条件は皆無
- ベースライン（シグナル未発生群）との二標本t検定（p=0.226）およびMann-Whitney検定（p=0.346）が非有意であり、シグナル群の超過リターンがランダム選択と有意に異ならない
- Cohen's d=0.158は小効果の閾値0.2を下回っており、実質的な効果の大きさが不十分
- 連続陽線日数を4日・5日に引き上げると平均超過リターンがほぼゼロまたは負に転じ（streak5_vol1.2: mean=-0.28%）、シグナルの頑健性が欠如している
- バックテストの累積リターン41.1%に対しベンチマーク40.0%と超過リターンはわずか約1.1%で、取引コストを考慮すれば実質的な優位性は消失する可能性が高い

**強み:**
- イベントスタディの設計が適切で、シグナル重複抑制（1ヶ月クーリング期間）によるルックアヘッドバイアス回避が実施されている
- ブートストラップ信頼区間（0.19%〜2.35%）がゼロを含まず、点推定の方向性自体は正の超過リターンを示唆している
- サンプルサイズ205件は最低限の統計的検出力を確保しており、セクター別・月別のサブグループ分析まで網羅的に実施されている
- 感度分析により9パターンのパラメータ組み合わせを検証し、結果の安定性を客観的に評価している

**弱み:**
- 非補正の一標本t検定のみが有意であり、複数の頑健性検定（Wilcoxon、二標本t検定、Mann-Whitney、Bonferroni補正）すべてで有意性を確認できない
- 勝率51.7%はランダム（50%）とほとんど変わらず、中央値の超過リターン0.72%も経済的に意味のある水準とは言い難い
- セクター間で極端なばらつき（建設+4.9%、機械+5.2% vs 情報通信-3.3%、医薬品-4.6%）があり、効果が特定セクターに偏在している可能性
- 月別分析でも9月（-4.0%、勝率15.4%）と12月（-1.9%、勝率30%）で大幅に負であり、季節性に脆弱
- バックテストのシャープ比2.0は一見良好だが、ベンチマーク自体が1.69と高い強気相場期間であり、相対的な付加価値は限定的
- 検証期間が1年間と短く、異なる市場環境（弱気相場・ボックス相場）での有効性が未確認

**改善提案:**
- 検証期間を最低5年以上に拡張し、異なる市場レジーム（上昇・下落・横ばい）でのシグナル有効性を確認すべき
- 取引コスト（往復0.1〜0.3%程度のスリッページ・手数料）を明示的に組み込んだネットリターンベースのバックテストを実施すべき
- セクターダミーや市場ボラティリティを制御変数としたクロスセクション回帰分析を行い、シグナル効果がセクター固有要因で説明されないか検証すべき
- FDR（False Discovery Rate）制御やBenjamini-Hochberg法による多重比較補正を適用し、データスヌーピングリスクを定量化すべき
- アウトオブサンプル検証として、期間を前半・後半に分割したウォークフォワード分析、またはTOPIX Large70やTOPIX Small等の別ユニバースでの検証を追加すべき
- Fama-French 3ファクターモデルやCarhart 4ファクターモデルによるリスク調整を行い、超過リターンがサイズ・バリュー・モメンタムファクターで説明されないか確認すべき

## 結論

**この仮説は追加検証が必要です。**

## 分析コード

```python
import pandas as pd
import numpy as np
from scipy import stats


def run_analysis(data_provider):
    # ============================================================
    # ステップ1: ユニバース確定（TOPIX Mid400）
    # ============================================================
    stocks_df = data_provider.get_listed_stocks()
    mid400 = stocks_df[stocks_df["scale_category"] == "TOPIX Mid400"].copy()
    universe_codes = mid400["code"].unique().tolist()

    # 銘柄数が多い場合はサンプリング（タイムアウト回避）
    np.random.seed(42)
    if len(universe_codes) > 50:
        universe_codes = sorted(np.random.choice(universe_codes, size=50, replace=False).tolist())

    sector_map = mid400.set_index("code")["sector_17_name"].to_dict()

    # ============================================================
    # ステップ2: 株価データ取得（助走期間含む）
    # ============================================================
    data_start = "2024-12-20"  # 助走期間（20日MA + 陽線判定用）
    data_end = "2026-02-23"
    signal_start = "2025-02-01"
    signal_end = "2026-01-31"  # シグナル検出最終日
    forward_days = 21  # 1ヶ月≒21営業日

    all_prices = []
    for code in universe_codes:
        try:
            df = data_provider.get_price_daily(code=code, start_date=data_start, end_date=data_end)
            if df is not None and len(df) > 0:
                all_prices.append(df)
        except Exception:
            continue

    if not all_prices:
        raise ValueError("株価データを取得できませんでした")

    prices_df = pd.concat(all_prices, ignore_index=True)
    prices_df["date"] = pd.to_datetime(prices_df["date"])
    prices_df.sort_values(["code", "date"], inplace=True)
    prices_df.reset_index(drop=True, inplace=True)

    # 実際に取得できた銘柄に絞る
    available_codes = prices_df["code"].unique().tolist()

    # ============================================================
    # TOPIX指数データ取得
    # ============================================================
    index_df = data_provider.get_index_prices(index_code="0000", start_date=data_start, end_date=data_end)
    index_df["date"] = pd.to_datetime(index_df["date"])
    index_df.sort_values("date", inplace=True)
    index_df["topix_return"] = index_df["close"].pct_change()
    index_df.set_index("date", inplace=True)

    # ============================================================
    # ステップ2-3: 陽線判定・出来高MA・シグナルフラグ
    # ============================================================
    def compute_signals(grp):
        g = grp.sort_values("date").copy()
        # 陽線判定（調整後終値 > 調整後始値）
        g["bullish"] = (g["adj_close"] > g["adj_open"]).astype(int)
        # 連続陽線カウント
        streak = []
        cnt = 0
        for b in g["bullish"].values:
            if b == 1:
                cnt += 1
            else:
                cnt = 0
            streak.append(cnt)
        g["bull_streak"] = streak
        # 出来高20日移動平均
        g["vol_ma20"] = g["adj_volume"].rolling(window=20, min_periods=20).mean()
        g["vol_ratio"] = g["adj_volume"] / g["vol_ma20"]
        # 日次リターン（調整後終値ベース）
        g["daily_return"] = g["adj_close"].pct_change()
        return g

    prices_df = prices_df.groupby("code", group_keys=False).apply(compute_signals)
    prices_df.reset_index(drop=True, inplace=True)

    # ============================================================
    # ステップ4: シグナル検出
    # ============================================================
    signal_mask = (
        (prices_df["date"] >= signal_start)
        & (prices_df["date"] <= signal_end)
        & (prices_df["bull_streak"] >= 3)
        & (prices_df["vol_ratio"] >= 1.2)
    )
    raw_signals = prices_df[signal_mask][["date", "code"]].copy()
    raw_signals.sort_values(["code", "date"], inplace=True)

    # 同一銘柄で1ヶ月以内の重複シグナルを除去
    filtered_signals = []
    last_signal = {}
    for _, row in raw_signals.iterrows():
        code = row["code"]
        dt = row["date"]
        if code in last_signal:
            if (dt - last_signal[code]).days < 30:
                continue
        last_signal[code] = dt
        filtered_signals.append(row)

    if not filtered_signals:
        # シグナルなしの場合、空の結果を返す
        return _empty_result(available_codes, data_start, data_end)

    signals_df = pd.DataFrame(filtered_signals)

    # ============================================================
    # ステップ5: フォワードリターン計算
    # ============================================================
    # 各銘柄の日付→行番号マップ作成
    prices_df["row_idx"] = range(len(prices_df))
    code_date_groups = {}
    for code in available_codes:
        sub = prices_df[prices_df["code"] == code].copy()
        sub = sub.set_index("date").sort_index()
        code_date_groups[code] = sub

    topix_dates = index_df.sort_index()

    results = []
    for _, sig in signals_df.iterrows():
        code = sig["code"]
        sig_date = sig["date"]
        if code not in code_date_groups:
            continue
        sub = code_date_groups[code]
        # シグナル日の翌営業日を探す
        future = sub[sub.index > sig_date]
        if len(future) < forward_days:
            continue
        entry_date = future.index[0]
        exit_date = future.index[forward_days - 1]
        entry_price = future.iloc[0]["adj_open"]  # 翌営業日始値
        exit_price = future.iloc[forward_days - 1]["adj_close"]  # 21営業日後終値

        if entry_price <= 0 or pd.isna(entry_price) or pd.isna(exit_price):
            continue

        stock_ret = (exit_price / entry_price) - 1.0

        # TOPIX同期間リターン
        topix_sub = topix_dates.loc[entry_date:exit_date]
        if len(topix_sub) < 2:
            continue
        topix_ret = (topix_sub["close"].iloc[-1] / topix_sub["close"].iloc[0]) - 1.0

        excess_ret = stock_ret - topix_ret

        results.append({
            "signal_date": sig_date,
            "entry_date": entry_date,
            "exit_date": exit_date,
            "code": code,
            "stock_return": stock_ret,
            "topix_return": topix_ret,
            "excess_return": excess_ret,
            "sector": sector_map.get(code, "不明"),
            "month": sig_date.month,
        })

    if not results:
        return _empty_result(available_codes, data_start, data_end)

    results_df = pd.DataFrame(results)

    # ============================================================
    # ステップ6: 記述統計
    # ============================================================
    excess = results_df["excess_return"].values
    n_signals = len(excess)
    mean_excess = float(np.mean(excess))
    median_excess = float(np.median(excess))
    std_excess = float(np.std(excess, ddof=1)) if n_signals > 1 else 0.0
    win_rate = float(np.mean(excess > 0))
    max_excess = float(np.max(excess))
    min_excess = float(np.min(excess))

    # ============================================================
    # ステップ7: コントロール群（ランダム1ヶ月リターン）
    # ============================================================
    np.random.seed(123)
    control_returns = []
    signal_dates_pd = pd.to_datetime(signals_df["date"].values)
    # ランダムに銘柄・日付を選んでコントロール群を構築
    ctrl_target = min(n_signals * 3, 300)
    ctrl_attempts = 0
    available_dates = prices_df[
        (prices_df["date"] >= signal_start) & (prices_df["date"] <= signal_end)
    ]["date"].unique()

    while len(control_returns) < ctrl_target and ctrl_attempts < ctrl_target * 10:
        ctrl_attempts += 1
        rand_code = np.random.choice(available_codes)
        rand_date = np.random.choice(available_dates)
        rand_date = pd.Timestamp(rand_date)
        if rand_code not in code_date_groups:
            continue
        sub = code_date_groups[rand_code]
        future = sub[sub.index > rand_date]
        if len(future) < forward_days:
            continue
        entry_price = future.iloc[0]["adj_open"]
        exit_price = future.iloc[forward_days - 1]["adj_close"]
        if entry_price <= 0 or pd.isna(entry_price) or pd.isna(exit_price):
            continue
        stock_ret = (exit_price / entry_price) - 1.0
        entry_d = future.index[0]
        exit_d = future.index[forward_days - 1]
        topix_sub = topix_dates.loc[entry_d:exit_d]
        if len(topix_sub) < 2:
            continue
        topix_ret = (topix_sub["close"].iloc[-1] / topix_sub["close"].iloc[0]) - 1.0
        control_returns.append(stock_ret - topix_ret)

    control_arr = np.array(control_returns) if control_returns else np.array([0.0])
    n_control = len(control_arr)
    mean_control = float(np.mean(control_arr))
    std_control = float(np.std(control_arr, ddof=1)) if n_control > 1 else 0.0
    win_rate_control = float(np.mean(control_arr > 0))

    # ============================================================
    # 統計検定
    # ============================================================
    # 1標本t検定
    if n_signals > 1:
        t1, p1 = stats.ttest_1samp(excess, 0)
    else:
        t1, p1 = 0.0, 1.0

    # Wilcoxon符号順位検定
    try:
        _, p_wilcox = stats.wilcoxon(excess)
    except Exception:
        p_wilcox = 1.0

    # 2標本t検定（シグナル群 vs コントロール群）
    if n_signals > 1 and n_control > 1:
        t2, p2 = stats.ttest_ind(excess, control_arr, equal_var=False)
    else:
        t2, p2 = 0.0, 1.0

    # Mann-Whitney U検定
    try:
        _, p_mw = stats.mannwhitneyu(excess, control_arr, alternative="two-sided")
    except Exception:
        p_mw = 1.0

    # Cohen's d
    if std_excess > 0:
        cohens_d = float(mean_excess / std_excess)
    else:
        cohens_d = 0.0

    # ブートストラップ信頼区間
    n_boot = 5000
    boot_means = []
    for _ in range(n_boot):
        sample = np.random.choice(excess, size=n_signals, replace=True)
        boot_means.append(np.mean(sample))
    boot_means = np.array(boot_means)
    ci_lower = float(np.percentile(boot_means, 2.5))
    ci_upper = float(np.percentile(boot_means, 97.5))

    # シャープレシオ（超過リターンベース、月次→年率換算）
    sharpe_excess = float(mean_excess / std_excess * np.sqrt(12)) if std_excess > 0 else 0.0

    # プロフィットファクター
    gains = excess[excess > 0]
    losses = excess[excess < 0]
    profit_factor = float(np.sum(gains) / abs(np.sum(losses))) if len(losses) > 0 and np.sum(losses) != 0 else float("inf") if len(gains) > 0 else 0.0

    # ============================================================
    # ステップ8: 感度分析
    # ============================================================
    sensitivity = {}
    for streak_th in [3, 4, 5]:
        for vol_th in [1.2, 1.5, 2.0]:
            key = f"streak{streak_th}_vol{vol_th}"
            smask = (
                (prices_df["date"] >= signal_start)
                & (prices_df["date"] <= signal_end)
                & (prices_df["bull_streak"] >= streak_th)
                & (prices_df["vol_ratio"] >= vol_th)
            )
            s_raw = prices_df[smask][["date", "code"]].copy()
            s_raw.sort_values(["code", "date"], inplace=True)
            s_filtered = []
            s_last = {}
            for _, r in s_raw.iterrows():
                c, d = r["code"], r["date"]
                if c in s_last and (d - s_last[c]).days < 30:
                    continue
                s_last[c] = d
                s_filtered.append(r)
            s_excess = []
            for r in s_filtered:
                c, d = r["code"], r["date"]
                if c not in code_date_groups:
                    continue
                sub = code_date_groups[c]
                fut = sub[sub.index > d]
                if len(fut) < forward_days:
                    continue
                ep = fut.iloc[0]["adj_open"]
                xp = fut.iloc[forward_days - 1]["adj_close"]
                if ep <= 0 or pd.isna(ep) or pd.isna(xp):
                    continue
                sr = (xp / ep) - 1.0
                ed, xd = fut.index[0], fut.index[forward_days - 1]
                ts = topix_dates.loc[ed:xd]
                if len(ts) < 2:
                    continue
                tr = (ts["close"].iloc[-1] / ts["close"].iloc[0]) - 1.0
                s_excess.append(sr - tr)
            s_arr = np.array(s_excess)
            n_s = len(s_arr)
            if n_s > 1:
                s_t, s_p = stats.ttest_1samp(s_arr, 0)
            else:
                s_t, s_p = 0.0, 1.0
            # Bonferroni補正 (9パターン)
            sensitivity[key] = {
                "n": n_s,
                "mean": float(np.mean(s_arr)) if n_s > 0 else 0.0,
                "p_value": float(s_p),
                "p_bonferroni": float(min(s_p * 9, 1.0)),
                "win_rate": float(np.mean(s_arr > 0)) if n_s > 0 else 0.0,
            }

    # ============================================================
    # ステップ9: セクター別・月別サブグループ分析
    # ============================================================
    sector_analysis = {}
    for sec, grp in results_df.groupby("sector"):
        vals = grp["excess_return"].values
        sector_analysis[sec] = {
            "n": len(vals),
            "mean": float(np.mean(vals)),
            "win_rate": float(np.mean(vals > 0)),
        }

    month_analysis = {}
    for m, grp in results_df.groupby("month"):
        vals = grp["excess_return"].values
        month_analysis[int(m)] = {
            "n": len(vals),
            "mean": float(np.mean(vals)),
            "win_rate": float(np.mean(vals > 0)),
        }

    # ============================================================
    # バックテスト（等金額ロング戦略、取引コスト片道10bps）
    # ============================================================
    tc = 0.001  # 片道10bps
    initial_capital = 10_000_000.0  # 1000万円

    # トレードログ構築
    trades = []
    for _, sig in results_df.iterrows():
        code = sig["code"]
        entry_d = sig["entry_date"]
        exit_d = sig["exit_date"]
        sub = code_date_groups[code]
        entry_price = float(sub.loc[entry_d, "adj_open"]) if entry_d in sub.index else None
        exit_price = float(sub.loc[exit_d, "adj_close"]) if exit_d in sub.index else None
        if entry_price is None or exit_price is None or entry_price <= 0:
            continue
        trades.append({
            "signal_date": sig["signal_date"],
            "entry_date": entry_d,
            "exit_date": exit_d,
            "code": code,
            "entry_price": entry_price,
            "exit_price": exit_price,
            "gross_return": (exit_price / entry_price) - 1.0,
            "net_return": (exit_price / entry_price) * (1 - tc) / (1 + tc) - 1.0,
        })

    trades_df = pd.DataFrame(trades) if trades else pd.DataFrame()

    # 日次エクイティカーブ構築
    all_biz_dates = sorted(prices_df[prices_df["date"] >= signal_start]["date"].unique())

    equity = initial_capital
    equity_curve = []
    active_positions = []  # list of dicts with code, entry_date, exit_date, weight, entry_price
    trade_log = []

    for biz_date in all_biz_dates:
        biz_date = pd.Timestamp(biz_date)
        # 決済処理
        new_active = []
        for pos in active_positions:
            if biz_date >= pos["exit_date"]:
                # 決済
                c = pos["code"]
                if c in code_date_groups:
                    sub = code_date_groups[c]
                    if pos["exit_date"] in sub.index:
                        exit_p = float(sub.loc[pos["exit_date"], "adj_close"])
                        ret = (exit_p / pos["entry_price"]) - 1.0
                        net_ret = (exit_p / pos["entry_price"]) * (1 - tc) / (1 + tc) - 1.0
                        pnl = pos["alloc"] * net_ret
                        equity += pnl
                        trade_log.append({
                            "date": str(pd.Timestamp(pos["exit_date"]).date()),
                            "code": c,
                            "action": "sell",
                            "shares": 0,
                            "price": exit_p,
                        })
            else:
                new_active.append(pos)
        active_positions = new_active

        # 新規エントリー（シグナル発生翌営業日）
        if len(trades_df) > 0:
            new_entries = trades_df[trades_df["entry_date"] == biz_date]
            # 既存ポジションの銘柄は除外
            active_codes = {p["code"] for p in active_positions}
            new_entries = new_entries[~new_entries["code"].isin(active_codes)]
            if len(new_entries) > 0:
                alloc_per_trade = equity / max(len(new_entries), 1) * 0.1  # 1トレード当たり資金の10%
                alloc_per_trade = min(alloc_per_trade, equity * 0.2)  # 上限20%
                for _, tr in new_entries.iterrows():
                    active_positions.append({
                        "code": tr["code"],
                        "entry_date": tr["entry_date"],
                        "exit_date": tr["exit_date"],
                        "entry_price": tr["entry_price"],
                        "alloc": alloc_per_trade,
                    })
                    trade_log.append({
                        "date": str(pd.Timestamp(biz_date).date()),
                        "code": tr["code"],
                        "action": "buy",
                        "shares": 0,
                        "price": tr["entry_price"],
                    })

        # 時価評価（簡易：保有中ポジションの当日評価）
        mtm_equity = equity
        for pos in active_positions:
            c = pos["code"]
            if c in code_date_groups:
                sub = code_date_groups[c]
                if biz_date in sub.index:
                    cur_p = float(sub.loc[biz_date, "adj_close"])
                    unrealized = pos["alloc"] * ((cur_p / pos["entry_price"]) - 1.0)
                    mtm_equity += unrealized

        equity_curve.append({
            "date": str(pd.Timestamp(biz_date).date()),
            "value": float(mtm_equity / initial_capital),
        })

    # ベンチマークカーブ（TOPIX）
    topix_curve_dates = topix_dates[topix_dates.index >= pd.Timestamp(signal_start)]
    if len(topix_curve_dates) > 0:
        topix_base = topix_curve_dates["close"].iloc[0]
        benchmark_curve = [
            {
                "date": str(pd.Timestamp(d).date()),
                "value": float(topix_curve_dates.loc[d, "close"] / topix_base),
            }
            for d in topix_curve_dates.index
        ]
    else:
        benchmark_curve = []

    # バックテスト統計
    if equity_curve:
        eq_values = [e["value"] for e in equity_curve]
        cumulative_return = float(eq_values[-1] - 1.0)
        n_days = len(eq_values)
        annual_return = float((1 + cumulative_return) ** (252 / max(n_days, 1)) - 1.0)
        daily_rets = np.diff(eq_values) / np.array(eq_values[:-1])
        sharpe = float(np.mean(daily_rets) / np.std(daily_rets) * np.sqrt(252)) if len(daily_rets) > 1 and np.std(daily_rets) > 0 else 0.0
        running_max = np.maximum.accumulate(eq_values)
        drawdowns = (np.array(eq_values) - running_max) / running_max
        max_dd = float(np.min(drawdowns))
    else:
        cumulative_return = 0.0
        annual_return = 0.0
        sharpe = 0.0
        max_dd = 0.0

    if benchmark_curve:
        bm_values = [b["value"] for b in benchmark_curve]
        bm_cum_ret = float(bm_values[-1] - 1.0)
        n_bm = len(bm_values)
        bm_annual = float((1 + bm_cum_ret) ** (252 / max(n_bm, 1)) - 1.0)
        bm_daily = np.diff(bm_values) / np.array(bm_values[:-1])
        bm_sharpe = float(np.mean(bm_daily) / np.std(bm_daily) * np.sqrt(252)) if len(bm_daily) > 1 and np.std(bm_daily) > 0 else 0.0
    else:
        bm_cum_ret = 0.0
        bm_annual = 0.0
        bm_sharpe = 0.0

    total_trades = len(trades)
    bt_win_rate = float(np.mean([t["net_return"] > 0 for t in trades])) if trades else 0.0

    # ============================================================
    # 結果辞書の構築
    # ============================================================
    result = {
        "statistics": {
            "test_name": "連続陽線・出来高急増シグナルの超過リターン検証（イベントスタディ）",
            "condition_mean": mean_excess,
            "baseline_mean": mean_control,
            "condition_std": std_excess,
            "baseline_std": std_control,
            "t_statistic": float(t1),
            "p_value": float(p1),
            "cohens_d": cohens_d,
            "win_rate_condition": win_rate,
            "win_rate_baseline": win_rate_control,
            "n_condition": n_signals,
            "n_baseline": n_control,
            "is_significant": bool(p1 < 0.05),
            # 追加統計
            "median_excess_return": median_excess,
            "max_excess_return": max_excess,
            "min_excess_return": min_excess,
            "sharpe_excess_annualized": sharpe_excess,
            "profit_factor": profit_factor,
            "wilcoxon_p_value": float(p_wilcox),
            "two_sample_t_statistic": float(t2),
            "two_sample_p_value": float(p2),
            "mann_whitney_p_value": float(p_mw),
            "bootstrap_ci_lower": ci_lower,
            "bootstrap_ci_upper": ci_upper,
            "sensitivity_analysis": sensitivity,
            "sector_analysis": sector_analysis,
            "month_analysis": month_analysis,
            "sufficient_sample_size": n_signals >= 30,
        },
        "backtest": {
            "cumulative_return": cumulative_return,
            "annual_return": annual_return,
            "sharpe_ratio": sharpe,
            "max_drawdown": max_dd,
            "win_rate": bt_win_rate,
            "total_trades": total_trades,
            "benchmark_cumulative_return": bm_cum_ret,
            "benchmark_annual_return": bm_annual,
            "benchmark_sharpe_ratio": bm_sharpe,
            "equity_curve": equity_curve,
            "benchmark_curve": benchmark_curve,
            "trade_log": trade_log,
        },
        "metadata": {
            "universe_codes": available_codes,
            "data_period": f"{data_start} ~ {data_end}",
            "description": (
                "TOPIX Mid400構成銘柄（サンプル50銘柄）において、陽線3日以上連続かつ"
                "出来高が直近20日平均の1.2倍以上に増加したシグナル発生後1ヶ月間の"
                "超過リターン（対TOPIX）を検証。1標本t検定・Wilcoxon検定・2標本比較・"
                "ブートストラップ信頼区間・感度分析・セクター/月別サブグループ分析を実施。"
                "バックテストは等金額ロング戦略（片道10bps取引コスト考慮）で評価。"
            ),
        },
    }

    return result


def _empty_result(codes, start, end):
    """シグナルが見つからなかった場合の空結果"""
    return {
        "statistics": {
            "test_name": "連続陽線・出来高急増シグナルの超過リターン検証（イベントスタディ）",
            "condition_mean": 0.0,
            "baseline_mean": 0.0,
            "condition_std": 0.0,
            "baseline_std": 0.0,
            "t_statistic": 0.0,
            "p_value": 1.0,
            "cohens_d": 0.0,
            "win_rate_condition": 0.0,
            "win_rate_baseline": 0.0,
            "n_condition": 0,
            "n_baseline": 0,
            "is_significant": False,
        },
        "backtest": {
            "cumulative_return": 0.0,
            "annual_return": 0.0,
            "sharpe_ratio": 0.0,
            "max_drawdown": 0.0,
            "win_rate": 0.0,
            "total_trades": 0,
            "benchmark_cumulative_return": 0.0,
            "benchmark_annual_return": 0.0,
            "benchmark_sharpe_ratio": 0.0,
            "equity_curve": [],
            "benchmark_curve": [],
            "trade_log": [],
        },
        "metadata": {
            "universe_codes": codes,
            "data_period": f"{start} ~ {end}",
            "description": "シグナルが検出されませんでした。",
        },
    }
```

---

_Knowledge ID: 1 | Run ID: 11 | 生成日: 2026-02-23 09:11:15_